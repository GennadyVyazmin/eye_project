# video_analytics_trassir_with_gallery.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
from deepface import DeepFace
import logging
import threading
from queue import Queue
from collections import deque, defaultdict
import os
import shutil

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class OptimizedTrassirCounter:
    def __init__(self, processing_interval=1.5, similarity_threshold=0.55, tracking_threshold=0.45):
        """
        –í–µ—Ä—Å–∏—è —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º —Ñ–æ—Ç–æ –∏ –≥–∞–ª–µ—Ä–µ–µ–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        """
        self.conn = sqlite3.connect('visitors_trassir_opt_v2.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.similarity_threshold = similarity_threshold
        self.tracking_threshold = tracking_threshold

        # –¶–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        self.COLORS = {
            'detected': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –ª–∏—Ü–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
            'tracking': (255, 255, 0),  # –ñ–µ–ª—Ç—ã–π - —Å–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫
            'known': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            'new': (0, 0, 255),  # –ö—Ä–∞—Å–Ω—ã–π - –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ë–î
            'analyzing': (255, 165, 0)  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –∞–Ω–∞–ª–∏–∑ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
        }

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
        self.photos_dir = "visitor_photos"
        self.current_session_dir = "current_session"
        self._create_directories()

        # –¢—Ä–µ–∫–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.last_processing_time = 0
        self.known_visitors_cache = {}
        self.frame_count = 0

        # –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
        self.face_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 3.0

        # –ì–∞–ª–µ—Ä–µ—è —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π –≤ –∫–∞–¥—Ä–µ
        self.current_visitors_gallery = {}  # {visitor_id: {'photo': image, 'last_seen': timestamp}}
        self.gallery_max_size = 8  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ –≤ –≥–∞–ª–µ—Ä–µ–µ
        self.photo_size = (120, 160)  # –†–∞–∑–º–µ—Ä —Ñ–æ—Ç–æ –≤ –≥–∞–ª–µ—Ä–µ–µ

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.recognition_stats = {
            'total_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'duplicates_prevented': 0
        }
        self.last_log_time = time.time()

        # –û—á–µ—Ä–µ–¥—å –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.frame_queue = Queue(maxsize=1)
        self.results_queue = Queue()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ª–∏—Ü
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self._load_known_visitors()

        # –ü–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_thread = None
        self.stop_processing = False

        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        logger.info(f"–£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –≥–∞–ª–µ—Ä–µ–µ–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π")

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω—ã –ø–∞–ø–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ: {self.photos_dir}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–ª–µ–º –¥–ª—è –ø—É—Ç–∏ –∫ —Ñ–æ—Ç–æ"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_embedding BLOB,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                confirmed_count INTEGER DEFAULT 1,
                photo_path TEXT
            )
        ''')
        self.conn.commit()

    def _load_known_visitors(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π –≤ –∫—ç—à"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT id, face_embedding, photo_path FROM visitors")
        visitors = cursor.fetchall()

        self.known_visitors_cache.clear()
        for visitor_id, embedding_blob, photo_path in visitors:
            if embedding_blob:
                try:
                    embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    self.known_visitors_cache[visitor_id] = {
                        'embedding': embedding,
                        'photo_path': photo_path
                    }
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {e}")

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π –∏–∑ –±–∞–∑—ã: {len(self.known_visitors_cache)}")

    def save_visitor_photo(self, face_image, visitor_id):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        try:
            # –°–æ–∑–¥–∞–µ–º —á–∏—Å—Ç—É—é –≤–µ—Ä—Å–∏—é —Ñ–æ—Ç–æ (–±–µ–∑ —Ä–∞–º–æ–∫ –∏ —Ç–µ–∫—Å—Ç–∞)
            photo_clean = face_image.copy()

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–µ–º–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            height, width = photo_clean.shape[:2]
            if width < 200:
                scale = 200 / width
                new_width = 200
                new_height = int(height * scale)
                photo_clean = cv2.resize(photo_clean, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ
            filename = f"visitor_{visitor_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
            filepath = os.path.join(self.photos_dir, filename)
            session_filepath = os.path.join(self.photos_dir, self.current_session_dir, filename)

            cv2.imwrite(filepath, photo_clean)
            cv2.imwrite(session_filepath, photo_clean)

            logger.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {filename}")
            return filepath

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ –¥–ª—è –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {e}")
            return None

    def update_visitor_gallery(self, visitor_id, face_image, status):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–∞–ª–µ—Ä–µ–∏ —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è –≥–∞–ª–µ—Ä–µ–∏
            gallery_photo = face_image.copy()

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–º–∫—É —Å—Ç–∞—Ç—É—Å–∞
            border_color = self.COLORS.get(status, (255, 255, 255))
            gallery_photo = cv2.copyMakeBorder(
                gallery_photo, 5, 25, 5, 5, cv2.BORDER_CONSTANT, value=border_color
            )

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å ID –∏ —Å—Ç–∞—Ç—É—Å–æ–º
            status_text = self.get_status_text(status)
            cv2.putText(gallery_photo, f"ID: {visitor_id}", (10, gallery_photo.shape[0] - 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, border_color, 1)

            # –†–µ—Å–∞–π–∑ –¥–ª—è –≥–∞–ª–µ—Ä–µ–∏
            gallery_photo = cv2.resize(gallery_photo, self.photo_size, interpolation=cv2.INTER_AREA)

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
            self.current_visitors_gallery[visitor_id] = {
                'photo': gallery_photo,
                'last_seen': time.time(),
                'status': status
            }

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –≥–∞–ª–µ—Ä–µ–∏
            if len(self.current_visitors_gallery) > self.gallery_max_size:
                # –£–¥–∞–ª—è–µ–º —Å–∞–º–æ–≥–æ —Å—Ç–∞—Ä–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è
                oldest_visitor = min(self.current_visitors_gallery.keys(),
                                     key=lambda x: self.current_visitors_gallery[x]['last_seen'])
                del self.current_visitors_gallery[oldest_visitor]

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")

    def create_gallery_display(self, main_frame):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–∞–ª–µ—Ä–µ–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π —Å–ø—Ä–∞–≤–∞ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            main_height, main_width = main_frame.shape[:2]

            # –°–æ–∑–¥–∞–µ–º –ø–∞–Ω–µ–ª—å –¥–ª—è –≥–∞–ª–µ—Ä–µ–∏
            gallery_width = 300
            gallery_panel = np.zeros((main_height, gallery_width, 3), dtype=np.uint8)

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥–∞–ª–µ—Ä–µ–∏
            cv2.putText(gallery_panel, "CURRENT VISITORS", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(gallery_panel, f"Total: {len(self.current_visitors_gallery)}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # –†–∞–∑–º–µ—â–∞–µ–º —Ñ–æ—Ç–æ –≤ –≥–∞–ª–µ—Ä–µ–µ
            if self.current_visitors_gallery:
                visitor_ids = sorted(self.current_visitors_gallery.keys())
                photos_per_column = 4
                photo_width, photo_height = self.photo_size
                margin = 10

                for i, visitor_id in enumerate(visitor_ids):
                    if i >= self.gallery_max_size:
                        break

                    visitor_data = self.current_visitors_gallery[visitor_id]
                    row = i % photos_per_column
                    col = i // photos_per_column

                    x = margin + col * (photo_width + margin)
                    y = 80 + row * (photo_height + margin)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ–±—ã —Ñ–æ—Ç–æ –ø–æ–º–µ—Å—Ç–∏–ª–æ—Å—å
                    if y + photo_height < main_height and x + photo_width < gallery_width:
                        gallery_panel[y:y + photo_height, x:x + photo_width] = visitor_data['photo']

                        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–µ–Ω—å–∫–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç—É—Å–∞
                        status_color = self.COLORS.get(visitor_data['status'], (255, 255, 255))
                        cv2.circle(gallery_panel, (x + 10, y + 10), 5, status_color, -1)
            else:
                # –°–æ–æ–±—â–µ–Ω–∏–µ –µ—Å–ª–∏ –≥–∞–ª–µ—Ä–µ—è –ø—É—Å—Ç–∞
                cv2.putText(gallery_panel, "No visitors", (50, main_height // 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 1)
                cv2.putText(gallery_panel, "in frame", (60, main_height // 2 + 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 1)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –≥–∞–ª–µ—Ä–µ–µ–π
            combined_frame = np.hstack([main_frame, gallery_panel])
            return combined_frame

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")
            return main_frame

    def resize_frame_for_display(self, frame, target_width=1280):
        """–£–º–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        height, width = frame.shape[:2]

        if width <= target_width:
            return frame

        ratio = target_width / width
        new_width = target_width
        new_height = int(height * ratio)

        resized_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)

        return resized_frame

    def log_recognition_stats(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        current_time = time.time()
        if current_time - self.last_log_time >= 5.0:
            logger.info(f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê: –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {len(self.known_visitors_cache)}, "
                        f"–ê–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤: {len(self.face_tracks)}, "
                        f"–í –≥–∞–ª–µ—Ä–µ–µ: {len(self.current_visitors_gallery)}, "
                        f"–ù–æ–≤—ã—Ö –∑–∞ —Å–µ—Å—Å–∏—é: {self.recognition_stats['new_visitors']}")

    def start_processing_thread(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.stop_processing = False
        self.processing_thread = threading.Thread(target=self._processing_worker, daemon=True)
        self.processing_thread.start()
        logger.info("–§–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—É—â–µ–Ω")

    def _processing_worker(self):
        """–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤"""
        while not self.stop_processing:
            try:
                frame_data = self.frame_queue.get(timeout=1.0)
                frame, frame_time = frame_data

                result = self._process_frame_heavy(frame)
                self.results_queue.put((result, frame_time))

                self.frame_queue.task_done()

            except:
                continue

    def _process_frame_heavy(self, frame):
        """–¢—è–∂–µ–ª—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–º"""
        try:
            # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            height, width = frame.shape[:2]
            if width > 640:
                scale = 640 / width
                new_width = 640
                new_height = int(height * scale)
                frame_small = cv2.resize(frame, (new_width, new_height))
            else:
                frame_small = frame

            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
            gray = cv2.cvtColor(frame_small, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=6,
                minSize=(60, 60),
                maxSize=(300, 300),
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            processed_faces = []
            if len(faces) > 0:
                logger.info(f"üë• –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü –≤ –∫–∞–¥—Ä–µ: {len(faces)}")

                for (x, y, w, h) in faces:
                    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ
                    scale_x = width / frame_small.shape[1]
                    scale_y = height / frame_small.shape[0]

                    x_orig = int(x * scale_x)
                    y_orig = int(y * scale_y)
                    w_orig = int(w * scale_x)
                    h_orig = int(h * scale_y)

                    if 60 <= w_orig <= 400 and 60 <= h_orig <= 400:
                        face_img = frame[y_orig:y_orig + h_orig, x_orig:x_orig + w_orig]

                        embedding = self.get_fast_embedding(face_img)
                        if embedding is not None:
                            visitor_id, similarity = self.find_best_match(embedding)

                            processed_faces.append({
                                'coords': (x_orig, y_orig, w_orig, h_orig),
                                'embedding': embedding,
                                'similarity': similarity,
                                'visitor_id': visitor_id,
                                'is_confirmed': similarity > self.similarity_threshold,
                                'status': 'detected',
                                'face_image': face_img  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–∏—Ü–∞
                            })

            return {
                'faces': processed_faces,
                'processed_count': len(processed_faces),
                'detected_count': len(faces),
                'timestamp': time.time()
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            return {'faces': [], 'processed_count': 0, 'detected_count': 0}

    def get_fast_embedding(self, face_image):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞"""
        try:
            face_resized = cv2.resize(face_image, (112, 112))
            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)

            lab = cv2.cvtColor(face_rgb, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l_enhanced = clahe.apply(l)
            lab_enhanced = cv2.merge([l_enhanced, a, b])
            face_normalized = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2RGB)

            result = DeepFace.represent(
                face_normalized,
                model_name='Facenet',
                enforce_detection=False,
                detector_backend='skip',
                align=True
            )

            embedding = np.array(result[0]['embedding'], dtype=np.float32)

            if np.all(embedding == 0) or np.linalg.norm(embedding) < 0.1:
                return None

            return embedding

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    def calculate_similarity(self, embedding1, embedding2):
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏"""
        if embedding1 is None or embedding2 is None:
            return 0.0

        try:
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            emb1_norm = embedding1 / norm1
            emb2_norm = embedding2 / norm2

            similarity = float(np.dot(emb1_norm, emb2_norm))
            return max(0.0, min(1.0, similarity))

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: {e}")
            return 0.0

    def find_best_match(self, embedding):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        if embedding is None:
            return None, 0.0

        best_match_id = None
        best_similarity = 0.0

        for visitor_id, visitor_data in self.known_visitors_cache.items():
            similarity = self.calculate_similarity(embedding, visitor_data['embedding'])
            if similarity > best_similarity:
                best_similarity = similarity
                best_match_id = visitor_id

        if best_similarity > self.tracking_threshold:
            return best_match_id, best_similarity

        return None, best_similarity

    def update_face_tracking(self, current_faces, timestamp):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏"""
        updated_faces = []

        for face_data in current_faces:
            embedding = face_data['embedding']
            coords = face_data['coords']
            face_image = face_data['face_image']

            best_track_id = None
            best_similarity = 0.0

            for track_id, track_data in list(self.face_tracks.items()):
                if timestamp - track_data['last_seen'] > self.track_max_age:
                    del self.face_tracks[track_id]
                    continue

                similarity = self.calculate_similarity(embedding, track_data['embedding'])
                if similarity > best_similarity and similarity > self.tracking_threshold:
                    best_similarity = similarity
                    best_track_id = track_id

            if best_track_id is not None:
                self.face_tracks[best_track_id].update({
                    'embedding': embedding,
                    'last_seen': timestamp,
                    'coords': coords,
                    'face_image': face_image
                })
                face_data['track_id'] = best_track_id
                face_data['visitor_id'] = self.face_tracks[best_track_id].get('visitor_id')
                face_data['status'] = 'tracking'
                logger.debug(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω —Ç—Ä–µ–∫ {best_track_id}, —Å—Ö–æ–∂–µ—Å—Ç—å: {best_similarity:.3f}")
            else:
                track_id = self.next_track_id
                self.next_track_id += 1
                self.face_tracks[track_id] = {
                    'embedding': embedding,
                    'last_seen': timestamp,
                    'coords': coords,
                    'face_image': face_image,
                    'visitor_id': None,
                    'created_at': timestamp,
                    'status': 'tracking'
                }
                face_data['track_id'] = track_id
                face_data['status'] = 'tracking'
                logger.info(f"üéØ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç—Ä–µ–∫ {track_id}")

            updated_faces.append(face_data)

        return updated_faces

    def confirm_visitor_identity(self, track_id, face_data):
        """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        track_data = self.face_tracks.get(track_id)
        if not track_data:
            return None

        embedding = face_data['embedding']
        face_image = face_data['face_image']
        timestamp = time.time()

        if track_data['visitor_id']:
            visitor_id = track_data['visitor_id']
            if visitor_id in self.known_visitors_cache:
                old_embedding = self.known_visitors_cache[visitor_id]['embedding']
                new_embedding = 0.7 * old_embedding + 0.3 * embedding
                self.known_visitors_cache[visitor_id]['embedding'] = new_embedding / np.linalg.norm(new_embedding)

            self.recognition_stats['known_visitors'] += 1
            face_data['status'] = 'known'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            self.update_visitor_gallery(visitor_id, face_image, 'known')

            logger.debug(f"‚ôªÔ∏è  –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id}")
            return visitor_id

        visitor_id, similarity = self.find_best_match(embedding)

        if similarity > self.similarity_threshold:
            track_data['visitor_id'] = visitor_id
            track_data['confirmed_at'] = timestamp
            self.recognition_stats['known_visitors'] += 1
            face_data['status'] = 'known'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
            self.update_visitor_gallery(visitor_id, face_image, 'known')

            logger.info(f"üë§ –û–ü–û–ó–ù–ê–ù –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id}, —Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f}")
            return visitor_id
        else:
            track_duration = timestamp - track_data['created_at']
            if track_duration > 2.0:
                new_visitor_id = self._create_new_visitor(embedding, face_image, track_id)
                if new_visitor_id:
                    self.recognition_stats['new_visitors'] += 1
                    face_data['status'] = 'new'

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
                    self.update_visitor_gallery(new_visitor_id, face_image, 'new')

                    logger.info(f"üÜï –°–û–ó–î–ê–ù –Ω–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {new_visitor_id}, —Å—Ö–æ–∂–µ—Å—Ç—å —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏: {similarity:.3f}")
                return new_visitor_id
            else:
                face_data['status'] = 'analyzing'
                logger.debug(f"‚è≥ –¢—Ä–µ–∫ {track_id} –æ–∂–∏–¥–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è ({track_duration:.1f}s)")

        return None

    def _create_new_visitor(self, embedding, face_image, track_id):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è —Å —Ñ–æ—Ç–æ"""
        cursor = self.conn.cursor()
        now = datetime.datetime.now()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ
        visitor_id = None
        try:
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å ID
            embedding_blob = embedding.astype(np.float32).tobytes()
            cursor.execute(
                """INSERT INTO visitors (face_embedding, first_seen, last_seen, 
                   visit_count, last_updated, confirmed_count, photo_path) 
                   VALUES (?, ?, ?, 1, ?, 1, ?)""",
                (embedding_blob, now, now, now, '')
            )
            visitor_id = cursor.lastrowid

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ
            photo_path = self.save_visitor_photo(face_image, visitor_id)

            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Å –ø—É—Ç–µ–º –∫ —Ñ–æ—Ç–æ
            cursor.execute(
                "UPDATE visitors SET photo_path = ? WHERE id = ?",
                (photo_path, visitor_id)
            )

            self.known_visitors_cache[visitor_id] = {
                'embedding': embedding,
                'photo_path': photo_path
            }
            self.conn.commit()

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è: {e}")
            self.conn.rollback()
            return None

        if track_id in self.face_tracks:
            self.face_tracks[track_id]['visitor_id'] = visitor_id

        return visitor_id

    def save_visitor_visit(self, visitor_id, embedding):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–∑–∏—Ç–∞ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        if visitor_id is None:
            return

        cursor = self.conn.cursor()
        now = datetime.datetime.now()

        cursor.execute(
            "UPDATE visitors SET last_seen = ?, visit_count = visit_count + 1, last_updated = ? WHERE id = ?",
            (now, now, visitor_id)
        )
        self.conn.commit()

    def get_color_by_status(self, status):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –ø–æ —Å—Ç–∞—Ç—É—Å—É"""
        return self.COLORS.get(status, (255, 255, 255))

    def get_status_text(self, status):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å—Ç–∞—Ç—É—Å—É"""
        status_texts = {
            'detected': 'DETECTED',
            'tracking': 'TRACKING',
            'analyzing': 'ANALYZING',
            'known': 'KNOWN',
            'new': 'NEW USER'
        }
        return status_texts.get(status, 'UNKNOWN')

    def setup_rtsp_camera(self, rtsp_url):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ RTSP"""
        logger.info(f"üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)

        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 15)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))

        for _ in range(5):
            cap.read()

        if cap.isOpened():
            ret, test_frame = cap.read()
            if ret:
                logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {test_frame.shape[1]}x{test_frame.shape[0]}")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")

        return cap

    def process_frame_realtime(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–º"""
        current_time = time.time()

        self.fps_frame_count += 1
        if current_time - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_frame_count / (current_time - self.fps_start_time)
            self.fps_frame_count = 0
            self.fps_start_time = current_time

        if current_time - self.last_processing_time < self.processing_interval:
            try:
                result, frame_time = self.results_queue.get_nowait()
                return self._apply_processing_result(frame, result, current_time)
            except:
                return frame, 0, 0

        if self.frame_queue.empty():
            self.frame_queue.put((frame.copy(), current_time))

        self.last_processing_time = current_time

        try:
            result, frame_time = self.results_queue.get_nowait()
            return self._apply_processing_result(frame, result, current_time)
        except:
            return frame, 0, 0

    def _apply_processing_result(self, frame, result, current_time):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç—Ä–µ–∫–∏–Ω–≥–æ–º –∏ —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π"""
        processed_frame = frame.copy()
        processed_count = 0

        tracked_faces = self.update_face_tracking(result['faces'], current_time)

        for face_data in tracked_faces:
            visitor_id = self.confirm_visitor_identity(face_data['track_id'], face_data)

            if visitor_id:
                self.save_visitor_visit(visitor_id, face_data['embedding'])

            x, y, w, h = face_data['coords']
            status = face_data.get('status', 'detected')

            # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç –∏ —Ç–µ–∫—Å—Ç –ø–æ —Å—Ç–∞—Ç—É—Å—É
            color = self.get_color_by_status(status)
            status_text = self.get_status_text(status)

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–∞–º–∫–∏ —Å —Ü–≤–µ—Ç–æ–º —Å—Ç–∞—Ç—É—Å–∞
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), color, 3)

            # –¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—É—Å–∞
            cv2.putText(processed_frame, f'{status_text}', (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            # ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if visitor_id:
                cv2.putText(processed_frame, f'ID: {visitor_id}', (x, y + h + 25),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

            processed_count += 1

        self.log_recognition_stats()

        return processed_frame, result['detected_count'], processed_count

    def start_analysis(self, rtsp_url):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –≥–∞–ª–µ—Ä–µ–µ–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≤–µ—Ä—Å–∏–∏ —Å –≥–∞–ª–µ—Ä–µ–µ–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π...")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        self.start_processing_thread()

        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ —Å –≥–∞–ª–µ—Ä–µ–µ–π –∑–∞–ø—É—â–µ–Ω")

        # –°–æ–∑–¥–∞–µ–º –æ–∫–Ω–æ
        window_name = 'Trassir Analytics - VISITOR GALLERY'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 900)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –æ–∫–Ω–æ –¥–ª—è –≥–∞–ª–µ—Ä–µ–∏

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("üì° –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–º–µ—Ä–æ–π...")
                    time.sleep(2)
                    continue

                processed_frame, detected, processed = self.process_frame_realtime(frame)

                display_frame = self.resize_frame_for_display(processed_frame, target_width=1280)

                # –î–æ–±–∞–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
                display_with_gallery = self.create_gallery_display(display_frame)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                stats_text = [
                    f"VISITOR ANALYTICS WITH GALLERY",
                    f"Detected: {detected}",
                    f"Processed: {processed}",
                    f"Total in DB: {len(self.known_visitors_cache)}",
                    f"In Gallery: {len(self.current_visitors_gallery)}",
                    f"FPS: {self.current_fps:.1f}",
                    f"Press 'q' to quit"
                ]

                # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                overlay = display_with_gallery.copy()
                cv2.rectangle(overlay, (0, 0), (500, 180), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.7, display_with_gallery, 0.3, 0, display_with_gallery)

                for i, text in enumerate(stats_text):
                    cv2.putText(display_with_gallery, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                cv2.imshow(window_name, display_with_gallery)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C...")
        finally:
            self.stop_processing = True
            if self.processing_thread:
                self.processing_thread.join(timeout=2.0)
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")
            logger.info(f"   –ù–æ–≤—ã—Ö —Å–æ–∑–¥–∞–Ω–æ –∑–∞ —Å–µ—Å—Å–∏—é: {self.recognition_stats['new_visitors']}")
            logger.info(f"   –§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {self.photos_dir}")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")

    def cleanup_database(self):
        """–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ç–æ"""
        cursor = self.conn.cursor()
        cursor.execute("DELETE FROM visitors")
        self.conn.commit()
        self.known_visitors_cache.clear()
        self.face_tracks.clear()
        self.current_visitors_gallery.clear()

        # –û—á–∏—â–∞–µ–º –ø–∞–ø–∫—É —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
        session_dir = os.path.join(self.photos_dir, self.current_session_dir)
        if os.path.exists(session_dir):
            shutil.rmtree(session_dir)
            os.makedirs(session_dir)

        logger.info("üóëÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ç–æ —Å–µ—Å—Å–∏–∏ –æ—á–∏—â–µ–Ω—ã")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = OptimizedTrassirCounter(
        processing_interval=1.5,
        similarity_threshold=0.55,
        tracking_threshold=0.45
    )

    # counter.cleanup_database()

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()