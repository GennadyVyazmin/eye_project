# video_analytics_trassir_enhanced.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
from deepface import DeepFace
import logging
import threading
from queue import Queue
from collections import deque, defaultdict
import os
import shutil

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('face_detection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class EnhancedTrassirCounter:
    def __init__(self, processing_interval=1.0, similarity_threshold=0.55, tracking_threshold=0.45):
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å MediaPipe –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        """
        self.conn = sqlite3.connect('visitors_trassir_enhanced.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.similarity_threshold = similarity_threshold
        self.tracking_threshold = tracking_threshold

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self.min_face_size = 80
        self.max_face_size = 300
        self.min_confidence = 0.7

        # –¶–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        self.COLORS = {
            'detected': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –ª–∏—Ü–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
            'tracking': (255, 255, 0),  # –ñ–µ–ª—Ç—ã–π - —Å–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫
            'known': (0, 255, 255),  # –ì–æ–ª—É–±–æ–π - –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            'new': (0, 0, 255),  # –ö—Ä–∞—Å–Ω—ã–π - –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ë–î
            'analyzing': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –∞–Ω–∞–ª–∏–∑ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
            'filtered': (128, 128, 128)  # –°–µ—Ä—ã–π - –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ
        }

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
        self.photos_dir = "visitor_photos_enhanced"
        self.current_session_dir = "current_session"
        self._create_directories()

        # –¢—Ä–µ–∫–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.last_processing_time = 0
        self.known_visitors_cache = {}
        self.frame_count = 0

        # –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü
        self.face_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 5.0

        # –ì–∞–ª–µ—Ä–µ—è —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self.current_visitors_gallery = {}
        self.gallery_max_size = 8
        self.photo_size = (120, 160)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recognition_stats = {
            'total_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'frames_processed': 0,
            'filtered_detections': 0
        }
        self.last_log_time = time.time()

        # –û—á–µ—Ä–µ–¥—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.frame_queue = Queue(maxsize=1)
        self.results_queue = Queue()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤
        self.setup_face_detection_models()

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self._load_known_visitors()

        # –ü–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_thread = None
        self.stop_processing = False

        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        logger.info("üéØ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å MediaPipe")

    def setup_face_detection_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe
            import mediapipe as mp
            self.mp_face_detection = mp.solutions.face_detection
            self.mp_drawing = mp.solutions.drawing_utils
            self.face_detection = self.mp_face_detection.FaceDetection(
                model_selection=0,  # 0 –¥–ª—è –±–ª–∏–∂–Ω–∏—Ö, 1 –¥–ª—è –¥–∞–ª—å–Ω–∏—Ö –ª–∏—Ü
                min_detection_confidence=0.5
            )
            self.use_mediapipe = True
            logger.info("‚úÖ MediaPipe –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü")
        except ImportError as e:
            self.use_mediapipe = False
            logger.warning(f"‚ùå MediaPipe –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenCV")

        # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–∞—Å–∫–∞–¥—ã OpenCV
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        self.alt_face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml'
        )

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω—ã –ø–∞–ø–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ: {self.photos_dir}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_embedding BLOB,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                confirmed_count INTEGER DEFAULT 1,
                photo_path TEXT
            )
        ''')
        self.conn.commit()

    def _load_known_visitors(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT id, face_embedding, photo_path FROM visitors")
        visitors = cursor.fetchall()

        self.known_visitors_cache.clear()
        for visitor_id, embedding_blob, photo_path in visitors:
            if embedding_blob:
                try:
                    embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    self.known_visitors_cache[visitor_id] = embedding
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {e}")

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")

    def detect_faces_mediapipe(self, frame):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MediaPipe"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detection.process(rgb_frame)

        faces = []
        if results.detections:
            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box
                h, w = frame.shape[:2]

                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)

                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º bounding box –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –∑–∞—Ö–≤–∞—Ç–∞
                x = max(0, x - 15)
                y = max(0, y - 15)
                width = min(w - x, width + 30)
                height = min(h - y, height + 30)

                confidence = detection.score[0]

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ä–∞–∑–º–µ—Ä—É
                if (confidence >= self.min_confidence and
                        width >= self.min_face_size and height >= self.min_face_size and
                        width <= self.max_face_size and height <= self.max_face_size):

                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                    if self.is_valid_face_region(frame, x, y, width, height):
                        faces.append((x, y, width, height))
                        logger.debug(f"‚úÖ MediaPipe –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence:.3f}")

        return faces

    def detect_faces_opencv(self, frame):
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å OpenCV"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # –û—Å–Ω–æ–≤–Ω–æ–π –∫–∞—Å–∫–∞–¥ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        faces1 = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.2,
            minNeighbors=7,
            minSize=(self.min_face_size, self.min_face_size),
            maxSize=(self.max_face_size, self.max_face_size),
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        valid_faces = []
        for (x, y, w, h) in faces1:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
            aspect_ratio = w / h
            if 0.7 < aspect_ratio < 1.8:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
                roi = gray[y:y + h, x:x + w]
                if self.is_likely_face(roi) and self.is_valid_face_region(frame, x, y, w, h):
                    valid_faces.append((x, y, w, h))

        return valid_faces

    def is_valid_face_region(self, frame, x, y, w, h):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ä–µ–≥–∏–æ–Ω–∞ –ª–∏—Ü–∞"""
        h_total, w_total = frame.shape[:2]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã—Ö–æ–¥–∞ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
        if x < 0 or y < 0 or x + w > w_total or y + h > h_total:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–∞)
        if w < w_total * 0.05 or h < h_total * 0.05:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π
            return False
        if w > w_total * 0.4 or h > h_total * 0.4:  # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
            return False

        return True

    def is_likely_face(self, face_roi):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ä–µ–≥–∏–æ–Ω –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –≤—Å–µ–≥–æ —è–≤–ª—è–µ—Ç—Å—è –ª–∏—Ü–æ–º"""
        if face_roi.size == 0:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞—Ä–∏–∞—Ü–∏–∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ (–ª–∏—Ü–∞ –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç –≤—ã—Å–æ–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç)
        std_dev = np.std(face_roi)
        if std_dev < 20:  # –°–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–∞—è —Ç–µ–∫—Å—Ç—É—Ä–∞ - –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–µ –ª–∏—Ü–æ
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        hist = cv2.calcHist([face_roi], [0], None, [8], [0, 256])
        hist = hist.flatten()
        if hist.sum() > 0:
            hist = hist / hist.sum()

        # –ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤ –≤ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–µ
        peak_count = 0
        for i in range(1, len(hist) - 1):
            if hist[i] > hist[i - 1] and hist[i] > hist[i + 1] and hist[i] > 0.1:
                peak_count += 1

        return peak_count >= 1

    def validate_human_features(self, face_image):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —á–µ–ª–æ–≤–µ–∫–∞"""
        if face_image.size == 0:
            return False

        h, w = face_image.shape[:2]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        if w < 50 or h < 50 or w > 400 or h > 400:
            return False

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–≤–µ—Ç–æ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–∫–æ–∂–∞ —á–µ–ª–æ–≤–µ–∫–∞)
            hsv = cv2.cvtColor(face_image, cv2.COLOR_BGR2HSV)

            # –ú–∞—Å–∫–∞ –¥–ª—è —Ü–≤–µ—Ç–æ–≤ –∫–æ–∂–∏
            skin_lower = np.array([0, 20, 70], dtype=np.uint8)
            skin_upper = np.array([20, 255, 255], dtype=np.uint8)
            skin_mask = cv2.inRange(hsv, skin_lower, skin_upper)

            # –ü—Ä–æ—Ü–µ–Ω—Ç –ø–∏–∫—Å–µ–ª–µ–π –∫–æ–∂–∏
            skin_ratio = np.sum(skin_mask > 0) / (w * h)

            # –î–ª—è –ª–∏—Ü –æ–±—ã—á–Ω–æ 15-50% –ø–∏–∫—Å–µ–ª–µ–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ü–≤–µ—Ç—É –∫–æ–∂–∏
            return 0.1 < skin_ratio < 0.7
        except:
            return True  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –¥–∞–µ–º —à–∞–Ω—Å

    def detect_faces_enhanced(self, frame):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º MediaPipe"""
        if self.use_mediapipe:
            faces = self.detect_faces_mediapipe(frame)
            if faces:
                logger.info(f"üîç MediaPipe: {len(faces)} –ª–∏—Ü")
                return faces

        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Å OpenCV
        faces = self.detect_faces_opencv(frame)
        logger.info(f"üîç OpenCV: {len(faces)} –ª–∏—Ü")

        return faces

    def get_fast_embedding(self, face_image):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞"""
        try:
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            face_resized = cv2.resize(face_image, (160, 160))
            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)

            result = DeepFace.represent(
                face_rgb,
                model_name='Facenet',
                enforce_detection=False,
                detector_backend='opencv',
                align=False
            )

            embedding = np.array(result[0]['embedding'], dtype=np.float32)

            if np.all(embedding == 0) or np.linalg.norm(embedding) < 0.1:
                return None

            return embedding

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    def calculate_similarity(self, embedding1, embedding2):
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –ª–∏—Ü"""
        if embedding1 is None or embedding2 is None:
            return 0.0

        try:
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            emb1_norm = embedding1 / norm1
            emb2_norm = embedding2 / norm2

            similarity = float(np.dot(emb1_norm, emb2_norm))
            return max(0.0, min(1.0, similarity))

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: {e}")
            return 0.0

    def find_best_match(self, embedding):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        if embedding is None:
            return None, 0.0

        best_match_id = None
        best_similarity = 0.0

        for visitor_id, known_embedding in self.known_visitors_cache.items():
            similarity = self.calculate_similarity(embedding, known_embedding)
            if similarity > best_similarity:
                best_similarity = similarity
                best_match_id = visitor_id

        return best_match_id, best_similarity

    def update_face_tracking(self, current_faces, timestamp):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏"""
        updated_faces = []

        for face_data in current_faces:
            embedding = face_data['embedding']
            coords = face_data['coords']
            face_image = face_data['face_image']

            best_track_id = None
            best_similarity = 0.0

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ç—Ä–µ–∫–∏
            for track_id in list(self.face_tracks.keys()):
                if timestamp - self.face_tracks[track_id]['last_seen'] > self.track_max_age:
                    logger.debug(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ç—Ä–µ–∫ {track_id}")
                    del self.face_tracks[track_id]

            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ç—Ä–µ–∫–∞–º–∏
            for track_id, track_data in self.face_tracks.items():
                similarity = self.calculate_similarity(embedding, track_data['embedding'])
                if similarity > best_similarity and similarity > self.tracking_threshold:
                    best_similarity = similarity
                    best_track_id = track_id

            if best_track_id is not None:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–∫
                self.face_tracks[best_track_id].update({
                    'embedding': embedding,
                    'last_seen': timestamp,
                    'coords': coords,
                    'face_image': face_image
                })
                face_data['track_id'] = best_track_id
                face_data['visitor_id'] = self.face_tracks[best_track_id].get('visitor_id')
                face_data['status'] = 'tracking'
                logger.debug(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω —Ç—Ä–µ–∫ {best_track_id}, —Å—Ö–æ–∂–µ—Å—Ç—å: {best_similarity:.3f}")
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–∫
                track_id = self.next_track_id
                self.next_track_id += 1
                self.face_tracks[track_id] = {
                    'embedding': embedding,
                    'last_seen': timestamp,
                    'coords': coords,
                    'face_image': face_image,
                    'visitor_id': None,
                    'created_at': timestamp
                }
                face_data['track_id'] = track_id
                face_data['status'] = 'tracking'
                logger.info(f"üéØ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç—Ä–µ–∫ {track_id}")

            updated_faces.append(face_data)

        return updated_faces

    def confirm_visitor_identity(self, track_id, face_data):
        """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        track_data = self.face_tracks.get(track_id)
        if not track_data:
            return None

        embedding = face_data['embedding']
        face_image = face_data['face_image']
        timestamp = time.time()

        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å visitor_id, –æ–±–Ω–æ–≤–ª—è–µ–º –µ–≥–æ
        if track_data['visitor_id']:
            visitor_id = track_data['visitor_id']
            self.recognition_stats['known_visitors'] += 1
            face_data['status'] = 'known'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
            self.update_visitor_gallery(visitor_id, face_image, 'known')

            logger.debug(f"‚ôªÔ∏è  –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id}")
            return visitor_id

        # –ò—â–µ–º –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å—Ä–µ–¥–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö
        visitor_id, similarity = self.find_best_match(embedding)

        if similarity > self.similarity_threshold:
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è
            track_data['visitor_id'] = visitor_id
            track_data['confirmed_at'] = timestamp
            self.recognition_stats['known_visitors'] += 1
            face_data['status'] = 'known'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
            self.update_visitor_gallery(visitor_id, face_image, 'known')

            logger.info(f"üë§ –û–ü–û–ó–ù–ê–ù –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id}, —Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f}")
            return visitor_id
        else:
            # –ñ–¥–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è
            track_duration = timestamp - track_data['created_at']
            if track_duration > 2.0:  # –ú–∏–Ω–∏–º—É–º 2 —Å–µ–∫—É–Ω–¥—ã —Ç—Ä–µ–∫–∏–Ω–≥–∞
                new_visitor_id = self._create_new_visitor(embedding, face_image, track_id)
                if new_visitor_id:
                    self.recognition_stats['new_visitors'] += 1
                    face_data['status'] = 'new'

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
                    self.update_visitor_gallery(new_visitor_id, face_image, 'new')

                    logger.info(f"üÜï –°–û–ó–î–ê–ù –Ω–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {new_visitor_id}, —Å—Ö–æ–∂–µ—Å—Ç—å —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏: {similarity:.3f}")
                return new_visitor_id
            else:
                face_data['status'] = 'analyzing'
                logger.debug(f"‚è≥ –¢—Ä–µ–∫ {track_id} –æ–∂–∏–¥–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è ({track_duration:.1f}s)")

        return None

    def _create_new_visitor(self, embedding, face_image, track_id):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        cursor = self.conn.cursor()
        now = datetime.datetime.now()

        visitor_id = None
        try:
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å
            photo_path = self.save_visitor_photo(face_image, "temp")

            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ
            embedding_blob = embedding.astype(np.float32).tobytes()
            cursor.execute(
                """INSERT INTO visitors (face_embedding, first_seen, last_seen, 
                   visit_count, last_updated, confirmed_count, photo_path) 
                   VALUES (?, ?, ?, 1, ?, 1, ?)""",
                (embedding_blob, now, now, now, photo_path)
            )
            visitor_id = cursor.lastrowid

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–æ—Ç–æ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º ID
            final_photo_path = self.save_visitor_photo(face_image, visitor_id)
            cursor.execute(
                "UPDATE visitors SET photo_path = ? WHERE id = ?",
                (final_photo_path, visitor_id)
            )

            self.known_visitors_cache[visitor_id] = embedding
            self.conn.commit()

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ
            if os.path.exists(photo_path):
                os.remove(photo_path)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è: {e}")
            self.conn.rollback()
            return None

        if track_id in self.face_tracks:
            self.face_tracks[track_id]['visitor_id'] = visitor_id

        return visitor_id

    def save_visitor_photo(self, face_image, visitor_id):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        try:
            photo_clean = face_image.copy()

            height, width = photo_clean.shape[:2]
            if width < 200:
                scale = 200 / width
                new_width = 200
                new_height = int(height * scale)
                photo_clean = cv2.resize(photo_clean, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)

            filename = f"visitor_{visitor_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
            filepath = os.path.join(self.photos_dir, filename)
            session_filepath = os.path.join(self.photos_dir, self.current_session_dir, filename)

            cv2.imwrite(filepath, photo_clean)
            cv2.imwrite(session_filepath, photo_clean)

            logger.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}")
            return filepath

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ: {e}")
            return ""

    def update_visitor_gallery(self, visitor_id, face_image, status):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–∞–ª–µ—Ä–µ–∏ —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            gallery_photo = face_image.copy()

            border_color = self.COLORS.get(status, (255, 255, 255))
            gallery_photo = cv2.copyMakeBorder(
                gallery_photo, 5, 25, 5, 5, cv2.BORDER_CONSTANT, value=border_color
            )

            status_text = self.get_status_text(status)
            cv2.putText(gallery_photo, f"ID: {visitor_id}", (10, gallery_photo.shape[0] - 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, border_color, 1)

            gallery_photo = cv2.resize(gallery_photo, self.photo_size, interpolation=cv2.INTER_AREA)

            self.current_visitors_gallery[visitor_id] = {
                'photo': gallery_photo,
                'last_seen': time.time(),
                'status': status
            }

            if len(self.current_visitors_gallery) > self.gallery_max_size:
                oldest_visitor = min(self.current_visitors_gallery.keys(),
                                     key=lambda x: self.current_visitors_gallery[x]['last_seen'])
                del self.current_visitors_gallery[oldest_visitor]

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")

    def get_status_text(self, status):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å—Ç–∞—Ç—É—Å—É"""
        status_texts = {
            'detected': 'DETECTED',
            'tracking': 'TRACKING',
            'analyzing': 'ANALYZING',
            'known': 'KNOWN',
            'new': 'NEW USER',
            'filtered': 'FILTERED'
        }
        return status_texts.get(status, 'UNKNOWN')

    def get_color_by_status(self, status):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –ø–æ —Å—Ç–∞—Ç—É—Å—É"""
        return self.COLORS.get(status, (255, 255, 255))

    def create_gallery_display(self, main_frame):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–∞–ª–µ—Ä–µ–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            main_height, main_width = main_frame.shape[:2]

            gallery_width = 300
            gallery_panel = np.zeros((main_height, gallery_width, 3), dtype=np.uint8)

            cv2.putText(gallery_panel, "CURRENT VISITORS", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(gallery_panel, f"Total: {len(self.current_visitors_gallery)}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            if self.current_visitors_gallery:
                visitor_ids = sorted(self.current_visitors_gallery.keys())
                photos_per_column = 4
                photo_width, photo_height = self.photo_size
                margin = 10

                for i, visitor_id in enumerate(visitor_ids):
                    if i >= self.gallery_max_size:
                        break

                    visitor_data = self.current_visitors_gallery[visitor_id]
                    row = i % photos_per_column
                    col = i // photos_per_column

                    x = margin + col * (photo_width + margin)
                    y = 80 + row * (photo_height + margin)

                    if y + photo_height < main_height and x + photo_width < gallery_width:
                        gallery_panel[y:y + photo_height, x:x + photo_width] = visitor_data['photo']

                        status_color = self.COLORS.get(visitor_data['status'], (255, 255, 255))
                        cv2.circle(gallery_panel, (x + 10, y + 10), 5, status_color, -1)
            else:
                cv2.putText(gallery_panel, "No visitors", (50, main_height // 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 1)
                cv2.putText(gallery_panel, "in frame", (60, main_height // 2 + 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 1)

            combined_frame = np.hstack([main_frame, gallery_panel])
            return combined_frame

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")
            return main_frame

    def resize_frame_for_display(self, frame, target_width=1280):
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        height, width = frame.shape[:2]

        if width <= target_width:
            return frame

        ratio = target_width / width
        new_width = target_width
        new_height = int(height * ratio)

        resized_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)

        return resized_frame

    def log_recognition_stats(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        current_time = time.time()
        if current_time - self.last_log_time >= 3.0:  # –ö–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
            logger.info(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê: –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {len(self.known_visitors_cache)}, "
                        f"–ê–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤: {len(self.face_tracks)}, "
                        f"–í –≥–∞–ª–µ—Ä–µ–µ: {len(self.current_visitors_gallery)}, "
                        f"–ù–æ–≤—ã—Ö –∑–∞ —Å–µ—Å—Å–∏—é: {self.recognition_stats['new_visitors']}, "
                        f"–ò–∑–≤–µ—Å—Ç–Ω—ã—Ö: {self.recognition_stats['known_visitors']}, "
                        f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {self.recognition_stats['filtered_detections']}")
            self.last_log_time = current_time

    def start_processing_thread(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.stop_processing = False
        self.processing_thread = threading.Thread(target=self._processing_worker, daemon=True)
        self.processing_thread.start()
        logger.info("–§–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—É—â–µ–Ω")

    def _processing_worker(self):
        """–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤"""
        while not self.stop_processing:
            try:
                frame_data = self.frame_queue.get(timeout=1.0)
                frame, frame_time = frame_data

                result = self._process_frame_heavy(frame)
                self.results_queue.put((result, frame_time))

                self.frame_queue.task_done()

            except:
                continue

    def _process_frame_heavy(self, frame):
        """–¢—è–∂–µ–ª—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        try:
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
            faces = self.detect_faces_enhanced(frame)

            processed_faces = []
            filtered_count = 0

            if len(faces) > 0:
                self.recognition_stats['total_detections'] += len(faces)
                logger.info(f"üë• –û–ë–ù–ê–†–£–ñ–ï–ù–û –û–ë–™–ï–ö–¢–û–í: {len(faces)}")

                for (x, y, w, h) in faces:
                    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
                    if not self.is_valid_face_region(frame, x, y, w, h):
                        filtered_count += 1
                        continue

                    face_img = frame[y:y + h, x:x + w]

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ–ª–æ–≤–µ–∫–∞
                    if not self.validate_human_features(face_img):
                        filtered_count += 1
                        logger.debug("‚ùå –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –Ω–µ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π –æ–±—ä–µ–∫—Ç")
                        continue

                    embedding = self.get_fast_embedding(face_img)
                    if embedding is not None:
                        visitor_id, similarity = self.find_best_match(embedding)

                        processed_faces.append({
                            'coords': (x, y, w, h),
                            'embedding': embedding,
                            'similarity': similarity,
                            'visitor_id': visitor_id,
                            'status': 'detected',
                            'face_image': face_img
                        })
                    else:
                        logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –ª–∏—Ü–∞")

            self.recognition_stats['filtered_detections'] += filtered_count

            return {
                'faces': processed_faces,
                'processed_count': len(processed_faces),
                'detected_count': len(faces),
                'filtered_count': filtered_count,
                'timestamp': time.time()
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            return {'faces': [], 'processed_count': 0, 'detected_count': 0, 'filtered_count': 0}

    def setup_rtsp_camera(self, rtsp_url):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ RTSP"""
        logger.info(f"üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)

        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 15)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä—ã –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        for _ in range(10):
            cap.read()

        if cap.isOpened():
            ret, test_frame = cap.read()
            if ret:
                logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {test_frame.shape[1]}x{test_frame.shape[0]}")
            else:
                logger.error("‚ùå –ö–∞–º–µ—Ä–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")

        return cap

    def process_frame_realtime(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        current_time = time.time()

        # –û–±–Ω–æ–≤–ª—è–µ–º FPS
        self.fps_frame_count += 1
        if current_time - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_frame_count / (current_time - self.fps_start_time)
            self.fps_frame_count = 0
            self.fps_start_time = current_time

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        if current_time - self.last_processing_time < self.processing_interval:
            try:
                result, frame_time = self.results_queue.get_nowait()
                return self._apply_processing_result(frame, result, current_time)
            except:
                return frame, 0, 0, 0

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        if self.frame_queue.empty():
            self.frame_queue.put((frame.copy(), current_time))

        self.last_processing_time = current_time

        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        try:
            result, frame_time = self.results_queue.get_nowait()
            return self._apply_processing_result(frame, result, current_time)
        except:
            return frame, 0, 0, 0

    def _apply_processing_result(self, frame, result, current_time):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        processed_frame = frame.copy()
        processed_count = 0

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫–∏–Ω–≥
        tracked_faces = self.update_face_tracking(result['faces'], current_time)

        for face_data in tracked_faces:
            visitor_id = self.confirm_visitor_identity(face_data['track_id'], face_data)

            x, y, w, h = face_data['coords']
            status = face_data.get('status', 'detected')

            color = self.get_color_by_status(status)
            status_text = self.get_status_text(status)

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–∞–º–∫–∏
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), color, 3)
            cv2.putText(processed_frame, f'{status_text}', (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            if visitor_id:
                cv2.putText(processed_frame, f'ID: {visitor_id}', (x, y + h + 25),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                cv2.putText(processed_frame, f'Sim: {face_data["similarity"]:.2f}',
                            (x, y + h + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            processed_count += 1

        self.log_recognition_stats()

        return processed_frame, result['detected_count'], processed_count, result['filtered_count']

    def start_analysis(self, rtsp_url):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ —Å MediaPipe...")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        self.start_processing_thread()
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω")

        window_name = 'Trassir Analytics - ENHANCED with MediaPipe'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 900)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("üì° –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–º–µ—Ä–æ–π...")
                    time.sleep(2)
                    continue

                processed_frame, detected, processed, filtered = self.process_frame_realtime(frame)
                display_frame = self.resize_frame_for_display(processed_frame, target_width=1280)
                display_with_gallery = self.create_gallery_display(display_frame)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                stats_text = [
                    f"ENHANCED ANALYTICS with MediaPipe",
                    f"Objects detected: {detected}",
                    f"Faces processed: {processed}",
                    f"Filtered: {filtered}",
                    f"Active tracks: {len(self.face_tracks)}",
                    f"In gallery: {len(self.current_visitors_gallery)}",
                    f"FPS: {self.current_fps:.1f}",
                    f"Press 'q' to quit"
                ]

                overlay = display_with_gallery.copy()
                cv2.rectangle(overlay, (0, 0), (500, 220), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.7, display_with_gallery, 0.3, 0, display_with_gallery)

                for i, text in enumerate(stats_text):
                    color = (255, 255, 255)
                    if "Filtered" in text and filtered > 0:
                        color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                    cv2.putText(display_with_gallery, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                cv2.imshow(window_name, display_with_gallery)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C...")
        finally:
            self.stop_processing = True
            if self.processing_thread:
                self.processing_thread.join(timeout=2.0)
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   –í—Å–µ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")
            logger.info(f"   –ù–æ–≤—ã—Ö —Å–æ–∑–¥–∞–Ω–æ: {self.recognition_stats['new_visitors']}")
            logger.info(f"   –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.recognition_stats['known_visitors']}")
            logger.info(f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {self.recognition_stats['filtered_detections']}")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = EnhancedTrassirCounter(
        processing_interval=1.0,
        similarity_threshold=0.55,
        tracking_threshold=0.45
    )

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()