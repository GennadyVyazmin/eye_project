# video_analytics_trassir_deepsort.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
from deepface import DeepFace
import logging
import threading
from queue import Queue
from collections import deque, defaultdict
import os
import shutil

# ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ DeepSORT
try:
    from deep_sort_realtime import DeepSort

    DEEPSORT_AVAILABLE = True
    logger.info("âœ… DeepSORT Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")
except ImportError:
    DEEPSORT_AVAILABLE = False
    logger.warning("âŒ DeepSORT Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³")

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AdvancedTrassirCounter:
    def __init__(self, processing_interval=1.0, similarity_threshold=0.55, tracking_threshold=0.45):
        """
        ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ñ DeepSORT Ð´Ð»Ñ Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³Ð° Ð¿Ð¾ Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸
        """
        self.conn = sqlite3.connect('visitors_trassir_advanced.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.similarity_threshold = similarity_threshold
        self.tracking_threshold = tracking_threshold

        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ DeepSORT
        self.deepsort = None
        if DEEPSORT_AVAILABLE:
            try:
                self.deepsort = DeepSort(
                    max_age=30,  # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð¶Ð¸Ð·Ð½Ð¸ Ñ‚Ñ€ÐµÐºÐ° Ð±ÐµÐ· Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ
                    n_init=3,  # ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ°Ð´Ñ€Ð¾Ð² Ð´Ð»Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ‚Ñ€ÐµÐºÐ°
                    max_cosine_distance=0.4,  # ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ðµ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´Ð»Ñ Ð°ÑÑÐ¾Ñ†Ð¸Ð°Ñ†Ð¸Ð¸
                    nn_budget=100  # Ð‘ÑŽÐ´Ð¶ÐµÑ‚ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸ Ð´Ð»Ñ Ð²Ð½ÐµÑˆÐ½Ð¸Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
                )
                logger.info("ðŸš€ DeepSORT Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð´Ð»Ñ Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³Ð° Ð¿Ð¾ Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸")
            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ DeepSORT: {e}")
                self.deepsort = None

        # Ð¦Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ†Ð¸Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑÐ¾Ð²
        self.COLORS = {
            'detected': (0, 255, 0),  # Ð—ÐµÐ»ÐµÐ½Ñ‹Ð¹ - Ð»Ð¸Ñ†Ð¾ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾
            'tracking': (255, 255, 0),  # Ð–ÐµÐ»Ñ‚Ñ‹Ð¹ - ÑÐ¾Ð·Ð´Ð°Ð½ Ñ‚Ñ€ÐµÐº
            'known': (0, 255, 255),  # Ð“Ð¾Ð»ÑƒÐ±Ð¾Ð¹ - Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ
            'new': (0, 0, 255),  # ÐšÑ€Ð°ÑÐ½Ñ‹Ð¹ - Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð² Ð‘Ð”
            'analyzing': (255, 165, 0),  # ÐžÑ€Ð°Ð½Ð¶ÐµÐ²Ñ‹Ð¹ - Ð°Ð½Ð°Ð»Ð¸Ð· Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ
            'deepsort': (255, 0, 255)  # ÐŸÑƒÑ€Ð¿ÑƒÑ€Ð½Ñ‹Ð¹ - Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³ DeepSORT
        }

        # ÐŸÐ°Ð¿ÐºÐ¸ Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ„Ð¾Ñ‚Ð¾
        self.photos_dir = "visitor_photos_advanced"
        self.current_session_dir = "current_session"
        self._create_directories()

        # Ð¢Ñ€ÐµÐºÐ¸Ð½Ð³ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
        self.last_processing_time = 0
        self.known_visitors_cache = {}
        self.frame_count = 0

        # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³Ð°
        self.face_tracks = {}
        self.deepsort_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 5.0

        # Ð“Ð°Ð»ÐµÑ€ÐµÑ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ñ… Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»ÐµÐ¹
        self.current_visitors_gallery = {}
        self.gallery_max_size = 8
        self.photo_size = (120, 160)

        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        self.recognition_stats = {
            'total_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'deepsort_matches': 0,
            'face_only_matches': 0
        }
        self.last_log_time = time.time()

        # ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        self.frame_queue = Queue(maxsize=1)
        self.results_queue = Queue()

        # Ð”ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ð»Ð¸Ñ†
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        # ÐŸÑ€ÐµÐ´Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ñ… Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»ÐµÐ¹
        self._load_known_visitors()

        # ÐŸÐ¾Ñ‚Ð¾Ðº Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        self.processing_thread = None
        self.stop_processing = False

        # Ð”Ð»Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        logger.info(f"ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð°Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ DeepSORT: {DEEPSORT_AVAILABLE}")

    def _create_directories(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¿Ð¾Ðº Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ„Ð¾Ñ‚Ð¾"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)

    def _init_database(self):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_embedding BLOB,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                confirmed_count INTEGER DEFAULT 1,
                photo_path TEXT,
                appearance_features BLOB
            )
        ''')
        self.conn.commit()

    def _load_known_visitors(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ñ… Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»ÐµÐ¹"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT id, face_embedding, photo_path, appearance_features FROM visitors")
        visitors = cursor.fetchall()

        self.known_visitors_cache.clear()
        for visitor_id, embedding_blob, photo_path, appearance_blob in visitors:
            if embedding_blob:
                try:
                    embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    appearance_features = np.frombuffer(appearance_blob, dtype=np.float32) if appearance_blob else None

                    self.known_visitors_cache[visitor_id] = {
                        'embedding': embedding,
                        'photo_path': photo_path,
                        'appearance_features': appearance_features
                    }
                except Exception as e:
                    logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»Ñ {visitor_id}: {e}")

        logger.info(f"ðŸ“Š Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»ÐµÐ¹: {len(self.known_visitors_cache)}")

    def extract_appearance_features(self, full_body_image):
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸ (Ð¾Ð´ÐµÐ¶Ð´Ð°, Ñ‚ÐµÐ»Ð¾ÑÐ»Ð¾Ð¶ÐµÐ½Ð¸Ðµ)"""
        try:
            if not DEEPSORT_AVAILABLE or self.deepsort is None:
                return None

            # DeepSORT Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¿Ñ€Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸
            # Ð—Ð´ÐµÑÑŒ Ð¼Ñ‹ Ð¼Ð¾Ð¶ÐµÐ¼ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ
            height, width = full_body_image.shape[:2]

            # ÐŸÑ€Ð¾ÑÑ‚Ñ‹Ðµ Ð³Ð¸ÑÑ‚Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ñ†Ð²ÐµÑ‚Ð° ÐºÐ°Ðº Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
            hsv = cv2.cvtColor(full_body_image, cv2.COLOR_BGR2HSV)
            hist_hue = cv2.calcHist([hsv], [0], None, [8], [0, 180])
            hist_sat = cv2.calcHist([hsv], [1], None, [4], [0, 256])
            hist_val = cv2.calcHist([hsv], [2], None, [4], [0, 256])

            # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð³Ð¸ÑÑ‚Ð¾Ð³Ñ€Ð°Ð¼Ð¼
            hist_hue = cv2.normalize(hist_hue, hist_hue).flatten()
            hist_sat = cv2.normalize(hist_sat, hist_sat).flatten()
            hist_val = cv2.normalize(hist_val, hist_val).flatten()

            # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
            appearance_features = np.concatenate([hist_hue, hist_sat, hist_val])
            return appearance_features.astype(np.float32)

        except Exception as e:
            logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸: {e}")
            return None

    def calculate_appearance_similarity(self, features1, features2):
        """Ð Ð°ÑÑ‡ÐµÑ‚ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ð¿Ð¾ Ð²Ð½ÐµÑˆÐ½Ð¸Ð¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼"""
        if features1 is None or features2 is None:
            return 0.0

        try:
            # ÐšÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð´Ð»Ñ Ð³Ð¸ÑÑ‚Ð¾Ð³Ñ€Ð°Ð¼Ð¼
            norm1 = np.linalg.norm(features1)
            norm2 = np.linalg.norm(features2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            similarity = np.dot(features1, features2) / (norm1 * norm2)
            return float(similarity)

        except Exception as e:
            logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸: {e}")
            return 0.0

    def process_with_deepsort(self, frame, faces):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÐºÐ°Ð´Ñ€Ð° Ñ DeepSORT"""
        if not DEEPSORT_AVAILABLE or self.deepsort is None:
            return []

        try:
            # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ DeepSORT
            detections = []
            for (x, y, w, h) in faces:
                # Ð Ð°ÑÑˆÐ¸Ñ€ÑÐµÐ¼ bounding box Ð´Ð»Ñ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ð° Ð±Ð¾Ð»ÑŒÑˆÐµÐ³Ð¾ ÑƒÑ‡Ð°ÑÑ‚ÐºÐ° Ñ‚ÐµÐ»Ð°
                expansion = 0.3  # 30% Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ
                x_exp = max(0, int(x - w * expansion))
                y_exp = max(0, int(y - h * expansion))
                w_exp = min(frame.shape[1] - x_exp, int(w * (1 + 2 * expansion)))
                h_exp = min(frame.shape[0] - y_exp, int(h * (1 + 2 * expansion)))

                confidence = 0.9  # Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ Ð»Ð¸Ñ†
                detections.append(([x_exp, y_exp, w_exp, h_exp], confidence, None))

            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ñ‚Ñ€ÐµÐºÐ¸ DeepSORT
            tracks = self.deepsort.update_tracks(detections, frame=frame)

            deepsort_results = []
            for track in tracks:
                if not track.is_confirmed():
                    continue

                track_id = track.track_id
                bbox = track.to_tlbr()  # [x1, y1, x2, y2]

                # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ [x, y, w, h]
                x = int(bbox[0])
                y = int(bbox[1])
                w = int(bbox[2] - bbox[0])
                h = int(bbox[3] - bbox[1])

                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸
                appearance_features = track.features if hasattr(track, 'features') else None

                deepsort_results.append({
                    'track_id': track_id,
                    'coords': (x, y, w, h),
                    'appearance_features': appearance_features,
                    'type': 'deepsort'
                })

                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÐºÑÑˆ Ñ‚Ñ€ÐµÐºÐ¾Ð² DeepSORT
                self.deepsort_tracks[track_id] = {
                    'coords': (x, y, w, h),
                    'appearance_features': appearance_features,
                    'last_seen': time.time()
                }

            return deepsort_results

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° DeepSORT: {e}")
            return []

    def match_face_with_deepsort(self, face_coords, face_embedding):
        """Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð»Ð¸Ñ†Ð° Ñ Ñ‚Ñ€ÐµÐºÐ°Ð¼Ð¸ DeepSORT"""
        if not self.deepsort_tracks:
            return None, 0.0

        face_x, face_y, face_w, face_h = face_coords
        face_center = (face_x + face_w // 2, face_y + face_h // 2)

        best_track_id = None
        best_similarity = 0.0

        for track_id, track_data in list(self.deepsort_tracks.items()):
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ Ñ‚Ñ€ÐµÐºÐ°
            if time.time() - track_data['last_seen'] > self.track_max_age:
                del self.deepsort_tracks[track_id]
                continue

            track_x, track_y, track_w, track_h = track_data['coords']
            track_center = (track_x + track_w // 2, track_y + track_h // 2)

            # Ð Ð°ÑÑ‡ÐµÑ‚ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð¼Ð¸
            distance = np.sqrt((face_center[0] - track_center[0]) ** 2 +
                               (face_center[1] - track_center[1]) ** 2)

            # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ (Ñ‡ÐµÐ¼ Ð¼ÐµÐ½ÑŒÑˆÐµ, Ñ‚ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐµ)
            max_distance = max(face_w, face_h, track_w, track_h)
            if max_distance > 0:
                normalized_distance = 1.0 - min(1.0, distance / max_distance)
            else:
                normalized_distance = 0.0

            # Ð•ÑÐ»Ð¸ Ñ†ÐµÐ½Ñ‚Ñ€Ñ‹ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð±Ð»Ð¸Ð·ÐºÐ¾, ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÑÑ‚Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸ÐµÐ¼
            if normalized_distance > 0.7:  # ÐŸÐ¾Ñ€Ð¾Ð³ Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚Ð¸
                if normalized_distance > best_similarity:
                    best_similarity = normalized_distance
                    best_track_id = track_id

        return best_track_id, best_similarity

    def combined_similarity_score(self, face_similarity, appearance_similarity, spatial_similarity):
        """ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸"""
        # Ð’ÐµÑÐ¾Ð²Ñ‹Ðµ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚Ñ‹
        face_weight = 0.6  # Ð›Ð¸Ñ†Ð¾ - ÑÐ°Ð¼Ñ‹Ð¹ Ð²Ð°Ð¶Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ðº
        appearance_weight = 0.3  # Ð’Ð½ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ (Ð¾Ð´ÐµÐ¶Ð´Ð°)
        spatial_weight = 0.1  # ÐŸÑ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ðµ Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ

        total_score = (face_similarity * face_weight +
                       appearance_similarity * appearance_weight +
                       spatial_similarity * spatial_weight)

        return total_score

    def find_best_combined_match(self, embedding, appearance_features, coords):
        """ÐŸÐ¾Ð¸ÑÐº Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ñ ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼Ð¸"""
        if embedding is None:
            return None, 0.0

        best_match_id = None
        best_combined_similarity = 0.0

        for visitor_id, visitor_data in self.known_visitors_cache.items():
            # Ð¡Ñ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð»Ð¸Ñ†
            face_similarity = self.calculate_similarity(embedding, visitor_data['embedding'])

            # Ð¡Ñ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸
            appearance_similarity = 0.0
            if appearance_features is not None and visitor_data['appearance_features'] is not None:
                appearance_similarity = self.calculate_appearance_similarity(
                    appearance_features, visitor_data['appearance_features']
                )

            # ÐŸÑ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ (Ð² Ð´Ð°Ð½Ð½Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ Ð½Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ)
            spatial_similarity = 0.5  # ÐÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ

            # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°
            combined_similarity = self.combined_similarity_score(
                face_similarity, appearance_similarity, spatial_similarity
            )

            if combined_similarity > best_combined_similarity:
                best_combined_similarity = combined_similarity
                best_match_id = visitor_id

        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¸Ð¿ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ
        if best_match_id:
            if best_combined_similarity > self.similarity_threshold:
                face_only_similarity = self.calculate_similarity(embedding,
                                                                 self.known_visitors_cache[best_match_id]['embedding'])
                if face_only_similarity < self.similarity_threshold:
                    self.recognition_stats['deepsort_matches'] += 1
                    logger.info(f"ðŸŽ¯ DeepSORT Ð¿Ð¾Ð¼Ð¾Ð³ Ð¾Ð¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {best_match_id}")
                else:
                    self.recognition_stats['face_only_matches'] += 1

        return best_match_id, best_combined_similarity

    def calculate_similarity(self, embedding1, embedding2):
        """Ð Ð°ÑÑ‡ÐµÑ‚ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ð»Ð¸Ñ†"""
        if embedding1 is None or embedding2 is None:
            return 0.0

        try:
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            emb1_norm = embedding1 / norm1
            emb2_norm = embedding2 / norm2

            similarity = float(np.dot(emb1_norm, emb2_norm))
            return max(0.0, min(1.0, similarity))

        except Exception as e:
            logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸: {e}")
            return 0.0

    # ... (Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ save_visitor_photo, update_visitor_gallery, create_gallery_display Ð¸ Ñ‚.Ð´.)
    # Ð¾ÑÑ‚Ð°ÑŽÑ‚ÑÑ Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¹ Ð²ÐµÑ€ÑÐ¸Ð¸, Ð½Ð¾ Ñ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ appearance_features

    def _create_new_visitor(self, embedding, face_image, appearance_features, track_id):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»Ñ Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼Ð¸ Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸"""
        cursor = self.conn.cursor()
        now = datetime.datetime.now()

        visitor_id = None
        try:
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ„Ð¾Ñ‚Ð¾
            photo_path = self.save_visitor_photo(face_image, visitor_id)

            # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
            embedding_blob = embedding.astype(np.float32).tobytes()
            appearance_blob = appearance_features.astype(
                np.float32).tobytes() if appearance_features is not None else None

            cursor.execute(
                """INSERT INTO visitors (face_embedding, first_seen, last_seen, 
                   visit_count, last_updated, confirmed_count, photo_path, appearance_features) 
                   VALUES (?, ?, ?, 1, ?, 1, ?, ?)""",
                (embedding_blob, now, now, now, photo_path, appearance_blob)
            )
            visitor_id = cursor.lastrowid

            self.known_visitors_cache[visitor_id] = {
                'embedding': embedding,
                'photo_path': photo_path,
                'appearance_features': appearance_features
            }
            self.conn.commit()

        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»Ñ: {e}")
            self.conn.rollback()
            return None

        if track_id in self.face_tracks:
            self.face_tracks[track_id]['visitor_id'] = visitor_id

        return visitor_id

    def start_analysis(self, rtsp_url):
        """Ð—Ð°Ð¿ÑƒÑÐº Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ DeepSORT"""
        logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸ Ñ DeepSORT...")

        if not DEEPSORT_AVAILABLE:
            logger.warning("âš ï¸  DeepSORT Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ: pip install deep-sort-realtime")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        self.start_processing_thread()
        logger.info("âœ… ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½")

        window_name = 'Trassir Analytics - DEEPSORT'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 900)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("ðŸ“¡ ÐŸÐ¾Ñ‚ÐµÑ€ÑÐ½Ð¾ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ...")
                    time.sleep(2)
                    continue

                processed_frame, detected, processed = self.process_frame_realtime(frame)
                display_frame = self.resize_frame_for_display(processed_frame, target_width=1280)
                display_with_gallery = self.create_gallery_display(display_frame)

                # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ DeepSORT
                stats_text = [
                    f"ADVANCED ANALYTICS WITH DEEPSORT",
                    f"Detected: {detected}",
                    f"Processed: {processed}",
                    f"DeepSORT: {'ON' if DEEPSORT_AVAILABLE else 'OFF'}",
                    f"DeepSORT matches: {self.recognition_stats['deepsort_matches']}",
                    f"Face matches: {self.recognition_stats['face_only_matches']}",
                    f"FPS: {self.current_fps:.1f}",
                    f"Press 'q' to quit"
                ]

                overlay = display_with_gallery.copy()
                cv2.rectangle(overlay, (0, 0), (550, 200), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.7, display_with_gallery, 0.3, 0, display_with_gallery)

                for i, text in enumerate(stats_text):
                    cv2.putText(display_with_gallery, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                cv2.imshow(window_name, display_with_gallery)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("â¹ï¸ ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°...")
        finally:
            self.stop_processing = True
            if self.processing_thread:
                self.processing_thread.join(timeout=2.0)
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            logger.info(f"ðŸ“Š Ð¤Ð˜ÐÐÐ›Ð¬ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
            logger.info(f"   Ð’ÑÐµÐ³Ð¾ Ð¿Ð¾ÑÐµÑ‚Ð¸Ñ‚ÐµÐ»ÐµÐ¹: {len(self.known_visitors_cache)}")
            logger.info(f"   Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð¿Ð¾ DeepSORT: {self.recognition_stats['deepsort_matches']}")
            logger.info(f"   Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ Ð»Ð¸Ñ†Ñƒ: {self.recognition_stats['face_only_matches']}")
            logger.info("âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½")


def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = AdvancedTrassirCounter(
        processing_interval=1.0,  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ð»Ð¸ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ñ‚Ñ€ÐµÐºÐ¸Ð½Ð³Ð°
        similarity_threshold=0.55,
        tracking_threshold=0.45
    )

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"âŒ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}")


if __name__ == "__main__":
    main()