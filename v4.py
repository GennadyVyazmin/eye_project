# video_analytics_trassir_final.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
from deepface import DeepFace
import logging
import threading
from queue import Queue
from collections import deque, defaultdict
import os
import shutil
import math
from threading import Lock

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('face_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class FastTrassirCounter:
    def __init__(self, processing_interval=1.5, similarity_threshold=0.65, tracking_threshold=0.50):
        """
        –ë–´–°–¢–†–ê–Ø –≤–µ—Ä—Å–∏—è —Å –±–æ–ª—å—à–∏–º –æ–∫–Ω–æ–º –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏
        """
        self.conn = sqlite3.connect('visitors_trassir_fast.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.similarity_threshold = similarity_threshold
        self.tracking_threshold = tracking_threshold

        # –ú—å—é—Ç–µ–∫—Å—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.stats_lock = Lock()
        self.tracks_lock = Lock()

        # –¶–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        self.COLORS = {
            'detected': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –ª–∏—Ü–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
            'tracking': (255, 255, 0),  # –ñ–µ–ª—Ç—ã–π - —Å–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫
            'known': (0, 255, 255),  # –ì–æ–ª—É–±–æ–π - –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            'new': (0, 0, 255),  # –ö—Ä–∞—Å–Ω—ã–π - –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ë–î
            'analyzing': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –∞–Ω–∞–ª–∏–∑ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
            'rejected': (128, 128, 128)  # –°–µ—Ä—ã–π - –æ—Ç—Å–µ—è–Ω –ª–æ–∂–Ω—ã–π –æ–±—ä–µ–∫—Ç
        }

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
        self.photos_dir = "visitor_photos_fast"
        self.current_session_dir = "current_session"
        self._create_directories()

        # –¢—Ä–µ–∫–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.last_processing_time = 0
        self.known_visitors_cache = {}
        self.frame_count = 0

        # –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü
        self.face_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 5.0  # –£–º–µ–Ω—å—à–∏–ª–∏ –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ —Ç—Ä–µ–∫–∞

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recognition_stats = {
            'total_detections': 0,
            'valid_detections': 0,
            'rejected_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'frames_processed': 0,
            'faces_processed': 0,
            'quality_rejections': defaultdict(int)
        }

        # –î–µ—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ü
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.last_face_processing_time = 0
        self.embedding_cache = {}
        self.cache_max_size = 100

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self._load_known_visitors()

        logger.info("üöÄ –ë–´–°–¢–†–ê–Ø —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω—ã –ø–∞–ø–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ: {self.photos_dir}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_embedding BLOB,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                confirmed_count INTEGER DEFAULT 1,
                photo_path TEXT,
                quality_score REAL DEFAULT 1.0
            )
        ''')
        self.conn.commit()

    def _load_known_visitors(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT id, face_embedding, photo_path FROM visitors")
        visitors = cursor.fetchall()

        self.known_visitors_cache.clear()
        for visitor_id, embedding_blob, photo_path in visitors:
            if embedding_blob:
                try:
                    embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    self.known_visitors_cache[visitor_id] = embedding
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {e}")

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")

    def setup_rtsp_camera(self, rtsp_url):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ RTSP –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏"""
        logger.info(f"üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ: {rtsp_url}")

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏
        cap = cv2.VideoCapture(rtsp_url)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 25)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–µ –∫–∞–¥—Ä—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –±—É—Ñ–µ—Ä–∞
        for _ in range(3):
            cap.read()

        if cap.isOpened():
            ret, test_frame = cap.read()
            if ret:
                logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {test_frame.shape[1]}x{test_frame.shape[0]}")
            else:
                logger.error("‚ùå –ö–∞–º–µ—Ä–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")

        return cap

    def resize_frame_fast(self, frame, max_width=1920):
        """–ë—ã—Å—Ç—Ä–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞"""
        h, w = frame.shape[:2]
        if w <= max_width:
            return frame

        scale = max_width / w
        new_w = max_width
        new_h = int(h * scale)

        return cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

    def detect_faces_fast(self, frame):
        """–°–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü"""
        try:
            # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω–æ
            small_frame = self.resize_frame_fast(frame, 960)  # 960px –≤–º–µ—Å—Ç–æ 640
            gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)

            # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=3,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è –±–æ–ª—å—à–µ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                minSize=(60, 60),  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                maxSize=(400, 400),
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ
            scale_x = frame.shape[1] / small_frame.shape[1]
            scale_y = frame.shape[0] / small_frame.shape[0]

            valid_faces = []
            for (x, y, w, h) in faces:
                scaled_bbox = (
                    int(x * scale_x),
                    int(y * scale_y),
                    int(w * scale_x),
                    int(h * scale_y)
                )

                # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                if w * scale_x >= 60 and h * scale_y >= 60:
                    valid_faces.append(scaled_bbox)
                    logger.info(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ: {int(w * scale_x)}x{int(h * scale_y)} –ø–∏–∫—Å")

            return valid_faces

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
            return []

    def get_embedding_fast(self, face_image):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —Ö—ç—à—É
            img_hash = hash(face_image.tobytes())
            if img_hash in self.embedding_cache:
                return self.embedding_cache[img_hash]

            # –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            face_resized = cv2.resize(face_image, (160, 160))
            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)

            result = DeepFace.represent(
                face_rgb,
                model_name='Facenet',
                enforce_detection=False,
                detector_backend='skip',
                align=False
            )

            embedding = np.array(result[0]['embedding'], dtype=np.float32)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
            if len(self.embedding_cache) >= self.cache_max_size:
                self.embedding_cache.clear()
            self.embedding_cache[img_hash] = embedding

            return embedding

        except Exception as e:
            logger.warning(f"‚ùå –û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    def calculate_similarity(self, embedding1, embedding2):
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        try:
            if embedding1 is None or embedding2 is None:
                return 0.0

            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            return np.dot(embedding1, embedding2) / (norm1 * norm2)
        except:
            return 0.0

    def find_best_match(self, embedding):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        best_match_id = None
        best_similarity = 0.0

        for visitor_id, known_embedding in self.known_visitors_cache.items():
            similarity = self.calculate_similarity(embedding, known_embedding)

            if similarity > best_similarity and similarity >= self.similarity_threshold:
                best_similarity = similarity
                best_match_id = visitor_id

        return best_match_id, best_similarity

    def update_face_tracking_fast(self, faces, current_time):
        """–ë—ã—Å—Ç—Ä–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞"""
        active_tracks = {}

        with self.tracks_lock:
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ç—Ä–µ–∫–æ–≤
            for track_id, track_info in list(self.face_tracks.items()):
                if current_time - track_info['last_seen'] > self.track_max_age:
                    del self.face_tracks[track_id]

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–æ–≤
            for face_bbox in faces:
                x, y, w, h = face_bbox
                face_center = (x + w // 2, y + h // 2)

                best_track_id = None
                best_distance = float('inf')

                for track_id, track_info in self.face_tracks.items():
                    if current_time - track_info['last_seen'] > 2.0:
                        continue

                    last_center = track_info['last_center']
                    distance = math.sqrt((face_center[0] - last_center[0]) ** 2 +
                                         (face_center[1] - last_center[1]) ** 2)

                    max_distance = min(w, h) * 2.0

                    if distance < best_distance and distance < max_distance:
                        best_distance = distance
                        best_track_id = track_id

                if best_track_id is not None:
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ç—Ä–µ–∫–∞
                    self.face_tracks[best_track_id].update({
                        'last_seen': current_time,
                        'last_center': face_center,
                        'bbox': face_bbox,
                        'confirmed_count': self.face_tracks[best_track_id].get('confirmed_count', 0) + 1
                    })
                    active_tracks[best_track_id] = self.face_tracks[best_track_id]
                else:
                    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç—Ä–µ–∫–∞
                    track_id = self.next_track_id
                    self.next_track_id += 1

                    self.face_tracks[track_id] = {
                        'first_seen': current_time,
                        'last_seen': current_time,
                        'last_center': face_center,
                        'bbox': face_bbox,
                        'confirmed_count': 1,
                        'status': 'detected'
                    }
                    active_tracks[track_id] = self.face_tracks[track_id]
                    logger.info(f"üÜï –°–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫ {track_id}")

        return active_tracks

    def process_face_recognition(self, track_info, face_roi, track_id):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            embedding = self.get_embedding_fast(face_roi)
            if embedding is None:
                return False

            visitor_id, similarity = self.find_best_match(embedding)

            if visitor_id is not None:
                # –ò–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å
                track_info['visitor_id'] = visitor_id
                track_info['status'] = 'known'
                track_info['similarity'] = similarity

                cursor = self.conn.cursor()
                cursor.execute('''
                    UPDATE visitors 
                    SET last_seen = ?, visit_count = visit_count + 1, last_updated = ?
                    WHERE id = ?
                ''', (datetime.datetime.now(), datetime.datetime.now(), visitor_id))
                self.conn.commit()

                with self.stats_lock:
                    self.recognition_stats['known_visitors'] += 1
                    self.recognition_stats['faces_processed'] += 1

                logger.info(f"üë§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å ID:{visitor_id} (—Å—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f})")
                return True
            else:
                # –ù–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å
                visitor_id = self.add_new_visitor(embedding, face_roi)
                if visitor_id:
                    track_info['visitor_id'] = visitor_id
                    track_info['status'] = 'new'

                    with self.stats_lock:
                        self.recognition_stats['new_visitors'] += 1
                        self.recognition_stats['faces_processed'] += 1

                    logger.info(f"üÜï –î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å ID:{visitor_id}")
                    return True

            return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return False

    def add_new_visitor(self, embedding, face_image):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        try:
            cursor = self.conn.cursor()

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ç–æ
            filename = f"visitor_{int(time.time())}.jpg"
            filepath = os.path.join(self.photos_dir, self.current_session_dir, filename)
            cv2.imwrite(filepath, face_image)

            cursor.execute('''
                INSERT INTO visitors 
                (face_embedding, first_seen, last_seen, last_updated, photo_path)
                VALUES (?, ?, ?, ?, ?)
            ''', (embedding.tobytes(), datetime.datetime.now(), datetime.datetime.now(),
                  datetime.datetime.now(), filepath))

            new_visitor_id = cursor.lastrowid
            self.conn.commit()

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
            self.known_visitors_cache[new_visitor_id] = embedding

            return new_visitor_id

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è: {e}")
            return None

    def process_frame_realtime(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –±–µ–∑ –∑–∞–¥–µ—Ä–∂–µ–∫"""
        current_time = time.time()

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ FPS –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
        self.fps_frame_count += 1
        if current_time - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_frame_count / (current_time - self.fps_start_time)
            self.fps_start_time = current_time
            self.fps_frame_count = 0

        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
        faces = self.detect_faces_fast(frame)

        # –¢—Ä–µ–∫–∏–Ω–≥
        active_tracks = self.update_face_tracking_fast(faces, current_time)

        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_frame = frame.copy()
        detected_count = len(active_tracks)
        processed_count = 0

        for track_id, track_info in active_tracks.items():
            x, y, w, h = track_info['bbox']

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –∏ —Å—Ç–∞—Ç—É—Å–∞
            status = track_info.get('status', 'detected')
            color = self.COLORS[status]

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ bounding box
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), color, 3)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
            if status == 'known':
                visitor_id = track_info.get('visitor_id', '?')
                similarity = track_info.get('similarity', 0)
                label = f"KNOWN ID:{visitor_id} ({similarity:.2f})"
            elif status == 'new':
                visitor_id = track_info.get('visitor_id', '?')
                label = f"NEW ID:{visitor_id}"
            else:
                conf_count = track_info.get('confirmed_count', 1)
                label = f"TRACK {track_id} ({conf_count})"

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å —Ñ–æ–Ω–æ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
            cv2.rectangle(processed_frame, (x, y - text_size[1] - 10),
                          (x + text_size[0], y), color, -1)
            cv2.putText(processed_frame, label, (x, y - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤
            if (track_info['confirmed_count'] >= 2 and
                    current_time - track_info.get('last_processed', 0) > self.processing_interval and
                    track_info.get('status') in [None, 'detected']):

                face_roi = frame[y:y + h, x:x + w]
                if self.process_face_recognition(track_info, face_roi, track_id):
                    processed_count += 1

                track_info['last_processed'] = current_time

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        with self.stats_lock:
            self.recognition_stats['total_detections'] += len(faces)
            self.recognition_stats['valid_detections'] += detected_count
            self.recognition_stats['frames_processed'] += 1

        return processed_frame, detected_count, processed_count

    def start_analysis(self, rtsp_url):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –±–æ–ª—å—à–∏–º –æ–∫–Ω–æ–º –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ë–´–°–¢–†–û–ô –≤–µ—Ä—Å–∏–∏...")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–µ –æ–∫–Ω–æ
        window_name = 'Trassir Analytics - FAST MODE'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 1200)  # –ë–æ–ª—å—à–æ–µ –æ–∫–Ω–æ

        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω!")

        try:
            while True:
                start_time = time.time()

                ret, frame = cap.read()
                if not ret:
                    logger.warning("üì° –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ...")
                    time.sleep(0.5)
                    continue

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
                processed_frame, detected, processed = self.process_frame_realtime(frame)

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—é
                display_frame = self.resize_frame_fast(processed_frame, 1600)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ (–∫—Ä—É–ø–Ω—ã–π —Ç–µ–∫—Å—Ç)
                stats_text = [
                    f"FAST MODE - REAL TIME",
                    f"FPS: {self.current_fps:.1f}",
                    f"Active Faces: {detected}",
                    f"Total Tracks: {len(self.face_tracks)}",
                    f"Faces Processed: {processed}",
                    f"Known: {self.recognition_stats['known_visitors']}",
                    f"New: {self.recognition_stats['new_visitors']}",
                    f"Press Q to quit"
                ]

                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å —Ñ–æ–Ω–æ–º
                for i, text in enumerate(stats_text):
                    y_position = 40 + i * 35
                    cv2.rectangle(display_frame, (10, y_position - 30),
                                  (600, y_position + 5), (0, 0, 0), -1)
                    cv2.putText(display_frame, text, (15, y_position),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

                cv2.imshow(window_name, display_frame)

                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C...")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   –°—Ä–µ–¥–Ω–∏–π FPS: {self.current_fps:.1f}")
            logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {self.recognition_stats['frames_processed']}")
            logger.info(f"   –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: {self.recognition_stats['valid_detections']}")
            logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ª–∏—Ü: {self.recognition_stats['faces_processed']}")
            logger.info(f"   –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö: {self.recognition_stats['known_visitors']}")
            logger.info(f"   –ù–æ–≤—ã—Ö: {self.recognition_stats['new_visitors']}")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = FastTrassirCounter(
        processing_interval=1.5,
        similarity_threshold=0.65,
        tracking_threshold=0.50
    )

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()