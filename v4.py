# video_analytics_trassir_realistic_fixed.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
from deepface import DeepFace
import logging
import threading
from queue import Queue
from collections import deque, defaultdict
import os
import shutil
import math
from threading import Lock

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RealisticTrassirCounter:
    def __init__(self, processing_interval=1.0, similarity_threshold=0.65, tracking_threshold=0.50):
        """
        –í–µ—Ä—Å–∏—è —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç –∫–∞–º–µ—Ä—ã
        """
        self.conn = sqlite3.connect('visitors_trassir_realistic.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.similarity_threshold = similarity_threshold
        self.tracking_threshold = tracking_threshold

        # –ú—å—é—Ç–µ–∫—Å—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.stats_lock = Lock()
        self.tracks_lock = Lock()
        self.gallery_lock = Lock()

        # –¶–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        self.COLORS = {
            'detected': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –ª–∏—Ü–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
            'tracking': (255, 255, 0),  # –ñ–µ–ª—Ç—ã–π - —Å–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫
            'known': (0, 255, 255),  # –ì–æ–ª—É–±–æ–π - –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            'new': (0, 0, 255),  # –ö—Ä–∞—Å–Ω—ã–π - –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ë–î
            'analyzing': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –∞–Ω–∞–ª–∏–∑ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
            'rejected': (128, 128, 128)  # –°–µ—Ä—ã–π - –æ—Ç—Å–µ—è–Ω –ª–æ–∂–Ω—ã–π –æ–±—ä–µ–∫—Ç
        }

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
        self.photos_dir = "visitor_photos_realistic"
        self.current_session_dir = "current_session"
        self._create_directories()

        # –¢—Ä–µ–∫–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.last_processing_time = 0
        self.known_visitors_cache = {}
        self.frame_count = 0

        # –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü
        self.face_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 8.0

        # –ì–∞–ª–µ—Ä–µ—è —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π —Å –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–æ–π
        self.current_visitors_gallery = {}
        self.gallery_max_size = 8
        self.gallery_cleanup_interval = 60.0
        self.last_gallery_cleanup = time.time()
        self.photo_size = (120, 160)

        # –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ï —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        self.false_positive_filter = {
            'min_face_ratio': 0.008,  # –û–ß–ï–ù–¨ –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞ (1-2% –∫–∞–¥—Ä–∞)
            'max_face_ratio': 0.30,  # –î–æ 30% –∫–∞–¥—Ä–∞ (–∫—Ä—É–ø–Ω—ã–π –ø–ª–∞–Ω)
            'min_aspect_ratio': 0.5,  # –®–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            'max_aspect_ratio': 2.0,
            'min_brightness': 15,  # –û—á–µ–Ω—å —Ç–µ–º–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            'max_brightness': 245,  # –û—á–µ–Ω—å —è—Ä–∫–∏–µ —É—Å–ª–æ–≤–∏—è
            'edge_threshold': 10,  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —á–µ—Ç–∫–æ—Å—Ç—å
            'required_confirmations': 2,
            'min_face_width': 40,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
            'min_face_height': 40  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recognition_stats = {
            'total_detections': 0,
            'valid_detections': 0,
            'rejected_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'frames_processed': 0,
            'quality_rejections': defaultdict(int)
        }
        self.last_log_time = time.time()

        # –û—á–µ—Ä–µ–¥—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.frame_queue = Queue(maxsize=2)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
        self.results_queue = Queue()

        # –î–µ—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ü —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –¥–∞–ª—å–Ω–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        self.alt_face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml'
        )

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self._load_known_visitors()

        # –ü–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_thread = None
        self.stop_processing = False

        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        logger.info("üéØ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω—ã –ø–∞–ø–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ: {self.photos_dir}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_embedding BLOB,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                confirmed_count INTEGER DEFAULT 1,
                photo_path TEXT,
                quality_score REAL DEFAULT 1.0
            )
        ''')
        self.conn.commit()

    def _load_known_visitors(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT id, face_embedding, photo_path FROM visitors")
        visitors = cursor.fetchall()

        self.known_visitors_cache.clear()
        for visitor_id, embedding_blob, photo_path in visitors:
            if embedding_blob:
                try:
                    embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    self.known_visitors_cache[visitor_id] = embedding
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {e}")

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")

    def setup_rtsp_camera(self, rtsp_url):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ RTSP –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        logger.info(f"üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)

        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 15)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))

        for _ in range(10):
            cap.read()

        if cap.isOpened():
            ret, test_frame = cap.read()
            if ret:
                logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {test_frame.shape[1]}x{test_frame.shape[0]}")
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                h, w = test_frame.shape[:2]
                logger.info(f"üìê –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –ª–∏—Ü –Ω–∞ —ç—Ç–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏:")
                logger.info(f"   - –ú–∞–ª–µ–Ω—å–∫–æ–µ –ª–∏—Ü–æ (–¥–∞–ª–µ–∫–æ): {int(w * 0.02)}x{int(h * 0.02)} –ø–∏–∫—Å–µ–ª–µ–π")
                logger.info(f"   - –°—Ä–µ–¥–Ω–µ–µ –ª–∏—Ü–æ: {int(w * 0.08)}x{int(h * 0.08)} –ø–∏–∫—Å–µ–ª–µ–π")
                logger.info(f"   - –ö—Ä—É–ø–Ω–æ–µ –ª–∏—Ü–æ (–±–ª–∏–∑–∫–æ): {int(w * 0.15)}x{int(h * 0.15)} –ø–∏–∫—Å–µ–ª–µ–π")
            else:
                logger.error("‚ùå –ö–∞–º–µ—Ä–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")

        return cap

    def analyze_face_quality(self, face_image, bbox, frame_size):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏"""
        try:
            x, y, w, h = bbox
            frame_height, frame_width = frame_size

            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ê–ë–°–û–õ–Æ–¢–ù–û–ì–û —Ä–∞–∑–º–µ—Ä–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö (–≤–∞–∂–Ω–µ–µ —á–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ)
            logger.debug(f"üìè –ê–±—Å–æ–ª—é—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {w}x{h} –ø–∏–∫—Å–µ–ª–µ–π")

            if w < self.false_positive_filter['min_face_width']:
                self.recognition_stats['quality_rejections']['small_width'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è —à–∏—Ä–∏–Ω–∞ ({w} < {self.false_positive_filter['min_face_width']})"
            if h < self.false_positive_filter['min_face_height']:
                self.recognition_stats['quality_rejections']['small_height'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –≤—ã—Å–æ—Ç–∞ ({h} < {self.false_positive_filter['min_face_height']})"

            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û–ì–û —Ä–∞–∑–º–µ—Ä–∞ (–≤—Ç–æ—Ä–∏—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π)
            face_area = w * h
            frame_area = frame_width * frame_height
            face_ratio = face_area / frame_area

            logger.debug(f"üìê –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {face_ratio:.4f} ({w}x{h} –ø–∏–∫—Å)")

            if face_ratio < self.false_positive_filter['min_face_ratio']:
                self.recognition_stats['quality_rejections']['small_ratio'] += 1
                # –ù–ï –æ—Ç–∫–ª–æ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∏–∑-–∑–∞ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è, –µ—Å–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π
                if w < 60 or h < 60:  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                    return False, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ ({face_ratio:.4f})"
                else:
                    logger.debug(f"‚ö†Ô∏è  –ú–∞–ª–µ–Ω—å–∫–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ, –Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä - –ø—Ä–∏–Ω–∏–º–∞–µ–º")

            if face_ratio > self.false_positive_filter['max_face_ratio']:
                self.recognition_stats['quality_rejections']['large_ratio'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ ({face_ratio:.4f})"

            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
            aspect_ratio = w / h
            logger.debug(f"‚öñÔ∏è –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω: {aspect_ratio:.2f}")

            if aspect_ratio < self.false_positive_filter['min_aspect_ratio']:
                self.recognition_stats['quality_rejections']['narrow'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º —É–∑–∫–æ–µ ({aspect_ratio:.2f})"
            if aspect_ratio > self.false_positive_filter['max_aspect_ratio']:
                self.recognition_stats['quality_rejections']['wide'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º —à–∏—Ä–æ–∫–æ–µ ({aspect_ratio:.2f})"

            # 4. –£–°–ò–õ–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏—Ü–æ (–∞ –Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π –æ–±—ä–µ–∫—Ç)
            gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —è—Ä–∫–æ—Å—Ç–∏
            brightness = np.mean(gray_face)
            logger.debug(f"üí° –Ø—Ä–∫–æ—Å—Ç—å: {brightness:.1f}")

            if brightness < self.false_positive_filter['min_brightness']:
                self.recognition_stats['quality_rejections']['dark'] += 1
                # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü –¥–æ–ø—É—Å–∫–∞–µ–º –º–µ–Ω—å—à—É—é —è—Ä–∫–æ—Å—Ç—å
                if w > 80:  # –¢–æ–ª—å–∫–æ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –ª–∏—Ü —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —è—Ä–∫–æ—Å—Ç–∏
                    return False, f"–°–ª–∏—à–∫–æ–º —Ç–µ–º–Ω–æ–µ ({brightness:.1f})"
                else:
                    logger.debug(f"‚ö†Ô∏è  –¢–µ–º–Ω–æ–µ, –Ω–æ –º–∞–ª–µ–Ω—å–∫–æ–µ –ª–∏—Ü–æ - –ø—Ä–∏–Ω–∏–º–∞–µ–º")

            if brightness > self.false_positive_filter['max_brightness']:
                self.recognition_stats['quality_rejections']['bright'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º —Å–≤–µ—Ç–ª–æ–µ ({brightness:.1f})"

            # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ç–∫–æ—Å—Ç–∏ (–¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∞—è)
            laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
            logger.debug(f"üîç –ß–µ—Ç–∫–æ—Å—Ç—å (–ª–∞–ø–ª–∞—Å–∏–∞–Ω): {laplacian_var:.1f}")

            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ —á–µ—Ç–∫–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–∏—Ü–∞
            dynamic_edge_threshold = max(self.false_positive_filter['edge_threshold'],
                                         min(30, 50 - w / 5))  # –ß–µ–º –º–µ–Ω—å—à–µ –ª–∏—Ü–æ, —Ç–µ–º –Ω–∏–∂–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

            if laplacian_var < dynamic_edge_threshold:
                self.recognition_stats['quality_rejections']['blurry'] += 1
                logger.debug(f"‚ö†Ô∏è  –ù–∏–∑–∫–∞—è —á–µ—Ç–∫–æ—Å—Ç—å ({laplacian_var:.1f} < {dynamic_edge_threshold:.1f}), –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
                # –ù–ï –æ—Ç–∫–ª–æ–Ω—è–µ–º –∏–∑-–∑–∞ —á–µ—Ç–∫–æ—Å—Ç–∏ –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü

            # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            contrast = np.std(gray_face)
            logger.debug(f"üé® –ö–æ–Ω—Ç—Ä–∞—Å—Ç: {contrast:.1f}")

            if contrast < 3:  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                self.recognition_stats['quality_rejections']['uniform'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–∞—è –æ–±–ª–∞—Å—Ç—å ({contrast:.1f})"

            # 7. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞: –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –æ—Ç—Å–µ–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            hist = cv2.calcHist([gray_face], [0], None, [8], [0, 256])
            hist_std = np.std(hist)
            if hist_std < 100 and w > 100:  # –î–ª—è –∫—Ä—É–ø–Ω—ã—Ö –ª–∏—Ü –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—ã
                self.recognition_stats['quality_rejections']['simple_texture'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–∞—è —Ç–µ–∫—Å—Ç—É—Ä–∞ ({hist_std:.1f})"

            return True, f"‚úÖ –õ–∏—Ü–æ {w}x{h} –ø–∏–∫—Å (—è—Ä–∫–æ—Å—Ç—å: {brightness:.1f}, —á–µ—Ç–∫–æ—Å—Ç—å: {laplacian_var:.1f})"

        except Exception as e:
            self.recognition_stats['quality_rejections']['error'] += 1
            return False, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {e}"

    def detect_faces_robust(self, frame):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –†–ê–ó–ù–´–• —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        frame_size = gray.shape

        all_faces = []

        # –ú–ù–û–ì–û–£–†–û–í–ù–ï–í–ê–Ø –¥–µ—Ç–µ–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –ª–∏—Ü
        detection_params = [
            # –£—Ä–æ–≤–µ–Ω—å 1: –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞ (–¥–∞–ª–µ–∫–∏–µ –ª—é–¥–∏)
            {
                'scaleFactor': 1.05,
                'minNeighbors': 3,
                'minSize': (20, 20),  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞
                'maxSize': (80, 80),
                'name': 'tiny_faces'
            },
            # –£—Ä–æ–≤–µ–Ω—å 2: –°—Ä–µ–¥–Ω–∏–µ –ª–∏—Ü–∞ (–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ)
            {
                'scaleFactor': 1.1,
                'minNeighbors': 4,
                'minSize': (40, 40),
                'maxSize': (150, 150),
                'name': 'medium_faces'
            },
            # –£—Ä–æ–≤–µ–Ω—å 3: –ö—Ä—É–ø–Ω—ã–µ –ª–∏—Ü–∞ (–±–ª–∏–∑–∫–æ –∫ –∫–∞–º–µ—Ä–µ)
            {
                'scaleFactor': 1.1,
                'minNeighbors': 5,
                'minSize': (80, 80),
                'maxSize': (300, 300),
                'name': 'large_faces'
            }
        ]

        total_raw_detections = 0
        valid_count = 0
        rejected_count = 0

        for params in detection_params:
            # –î–µ—Ç–µ–∫—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã–º –∫–∞—Å–∫–∞–¥–æ–º
            faces1 = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=params['scaleFactor'],
                minNeighbors=params['minNeighbors'],
                minSize=params['minSize'],
                maxSize=params['maxSize'],
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            # –î–µ—Ç–µ–∫—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º –∫–∞—Å–∫–∞–¥–æ–º
            faces2 = self.alt_face_cascade.detectMultiScale(
                gray,
                scaleFactor=params['scaleFactor'],
                minNeighbors=params['minNeighbors'] - 1,  # –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π
                minSize=params['minSize'],
                maxSize=params['maxSize'],
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            total_raw_detections += len(faces1) + len(faces2)
            logger.debug(f"üîç {params['name']}: –æ—Å–Ω–æ–≤–Ω–æ–π {len(faces1)}, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π {len(faces2)}")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            face_set = set()

            for faces in [faces1, faces2]:
                for (x, y, w, h) in faces:
                    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –±–ª–∏–∑–∫–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
                    face_key = (x // 15, y // 15, w // 15, h // 15)
                    if face_key in face_set:
                        continue

                    face_set.add(face_key)

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ª–∏—Ü–∞
                    face_roi = frame[y:y + h, x:x + w]
                    is_valid, quality_msg = self.analyze_face_quality(face_roi, (x, y, w, h), frame_size)

                    if is_valid:
                        all_faces.append((x, y, w, h))
                        valid_count += 1
                        logger.info(f"‚úÖ –ü—Ä–∏–Ω—è—Ç–æ {params['name']} {w}x{h}: {quality_msg}")
                    else:
                        rejected_count += 1
                        if w >= 40:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
                            logger.info(f"‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–æ {params['name']} {w}x{h}: {quality_msg}")

        logger.info(
            f"üìä –ú–ù–û–ì–û–£–†–û–í–ù–ï–í–ê–Ø –¥–µ—Ç–µ–∫—Ü–∏—è: —Å—ã—Ä—ã—Ö {total_raw_detections}, –ø—Ä–∏–Ω—è—Ç–æ {valid_count}, –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ {rejected_count}")

        with self.stats_lock:
            self.recognition_stats['rejected_detections'] += rejected_count

        return all_faces

    def get_fast_embedding(self, face_image):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ø–æ–¥ –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞"""
        try:
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–µ—Å–∞–π–∑ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–∏—Ü–∞
            h, w = face_image.shape[:2]

            if w < 60 or h < 60:
                # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π
                target_size = max(80, min(w, h))
                face_resized = cv2.resize(face_image, (target_size, target_size))
                logger.debug(f"üîç –ú–∞–ª–µ–Ω—å–∫–æ–µ –ª–∏—Ü–æ {w}x{h}, —Ä–µ—Å–∞–π–∑ –¥–æ {target_size}x{target_size}")
            else:
                # –î–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –ª–∏—Ü —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                face_resized = cv2.resize(face_image, (160, 160))

            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)

            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            result = DeepFace.represent(
                face_rgb,
                model_name='Facenet',
                enforce_detection=False,
                detector_backend='opencv',
                align=False
            )

            embedding = np.array(result[0]['embedding'], dtype=np.float32)

            # –ú—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            if np.all(embedding == 0):
                logger.warning("‚ùå –ù—É–ª–µ–≤–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥")
                return None

            norm = np.linalg.norm(embedding)
            if norm < 0.005:  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                logger.warning(f"‚ùå –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –Ω–æ—Ä–º–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {norm}")
                return None

            logger.debug(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω, –Ω–æ—Ä–º–∞: {norm:.4f}")
            return embedding

        except Exception as e:
            logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    def calculate_similarity(self, embedding1, embedding2):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
        try:
            if embedding1 is None or embedding2 is None:
                return 0.0

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)

            if norm1 == 0 or norm2 == 0:
                return 0.0

            embedding1_norm = embedding1 / norm1
            embedding2_norm = embedding2 / norm2

            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarity = np.dot(embedding1_norm, embedding2_norm)

            return float(similarity)
        except Exception as e:
            logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}")
            return 0.0

    def find_best_match(self, embedding):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        best_match_id = None
        best_similarity = 0.0

        for visitor_id, known_embedding in self.known_visitors_cache.items():
            similarity = self.calculate_similarity(embedding, known_embedding)

            if similarity > best_similarity and similarity >= self.similarity_threshold:
                best_similarity = similarity
                best_match_id = visitor_id

        return best_match_id, best_similarity

    def update_face_tracking(self, faces, current_time):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü"""
        active_tracks = {}

        with self.tracks_lock:
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ç—Ä–µ–∫–æ–≤
            for track_id, track_info in list(self.face_tracks.items()):
                if current_time - track_info['last_seen'] > self.track_max_age:
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ç—Ä–µ–∫ {track_id}")
                    del self.face_tracks[track_id]

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç—Ä–µ–∫–æ–≤
            for face_bbox in faces:
                x, y, w, h = face_bbox
                face_center = (x + w // 2, y + h // 2)

                best_track_id = None
                best_distance = float('inf')

                # –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ç—Ä–µ–∫–∞
                for track_id, track_info in self.face_tracks.items():
                    if current_time - track_info['last_seen'] > 1.0:
                        continue

                    last_center = track_info['last_center']
                    distance = math.sqrt((face_center[0] - last_center[0]) ** 2 +
                                         (face_center[1] - last_center[1]) ** 2)

                    # –ü–æ—Ä–æ–≥–æ–≤–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏
                    max_distance = min(w, h) * 1.5

                    if distance < best_distance and distance < max_distance:
                        best_distance = distance
                        best_track_id = track_id

                if best_track_id is not None:
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ç—Ä–µ–∫–∞
                    self.face_tracks[best_track_id].update({
                        'last_seen': current_time,
                        'last_center': face_center,
                        'bbox': face_bbox,
                        'confirmed_count': self.face_tracks[best_track_id].get('confirmed_count', 0) + 1
                    })
                    active_tracks[best_track_id] = self.face_tracks[best_track_id]
                else:
                    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç—Ä–µ–∫–∞
                    track_id = self.next_track_id
                    self.next_track_id += 1

                    self.face_tracks[track_id] = {
                        'first_seen': current_time,
                        'last_seen': current_time,
                        'last_center': face_center,
                        'bbox': face_bbox,
                        'confirmed_count': 1,
                        'status': 'detected'
                    }
                    active_tracks[track_id] = self.face_tracks[track_id]
                    logger.info(f"üÜï –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç—Ä–µ–∫ {track_id}")

        return active_tracks

    def save_visitor_photo(self, face_image, visitor_id):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        try:
            filename = f"visitor_{visitor_id}_{int(time.time())}.jpg"
            filepath = os.path.join(self.photos_dir, self.current_session_dir, filename)

            cv2.imwrite(filepath, face_image)
            logger.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ: {e}")
            return None

    def update_visitor_database(self, embedding, face_image, track_id):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            # –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            visitor_id, similarity = self.find_best_match(embedding)
            current_time = datetime.datetime.now()

            if visitor_id is not None:
                # –ò–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å
                cursor = self.conn.cursor()
                cursor.execute('''
                    UPDATE visitors 
                    SET last_seen = ?, visit_count = visit_count + 1, last_updated = ?
                    WHERE id = ?
                ''', (current_time, current_time, visitor_id))
                self.conn.commit()

                with self.stats_lock:
                    self.recognition_stats['known_visitors'] += 1

                logger.info(f"üë§ –û–±–Ω–æ–≤–ª–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id} (—Å—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f})")
                return visitor_id, 'known'
            else:
                # –ù–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å
                cursor = self.conn.cursor()
                photo_path = self.save_visitor_photo(face_image, self.next_track_id)

                cursor.execute('''
                    INSERT INTO visitors 
                    (face_embedding, first_seen, last_seen, last_updated, photo_path)
                    VALUES (?, ?, ?, ?, ?)
                ''', (embedding.tobytes(), current_time, current_time, current_time, photo_path))

                new_visitor_id = cursor.lastrowid
                self.conn.commit()

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
                self.known_visitors_cache[new_visitor_id] = embedding

                with self.stats_lock:
                    self.recognition_stats['new_visitors'] += 1

                logger.info(f"üÜï –î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {new_visitor_id}")
                return new_visitor_id, 'new'

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î: {e}")
            return None, 'error'

    def process_frame_realtime(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        current_time = time.time()

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ FPS
        self.fps_frame_count += 1
        if current_time - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_frame_count / (current_time - self.fps_start_time)
            self.fps_start_time = current_time
            self.fps_frame_count = 0

        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
        faces = self.detect_faces_robust(frame)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞
        active_tracks = self.update_face_tracking(faces, current_time)

        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        processed_frame = frame.copy()

        detected_count = 0
        processed_count = 0

        for track_id, track_info in active_tracks.items():
            x, y, w, h = track_info['bbox']

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –¥–ª—è —Ü–≤–µ—Ç–∞
            if track_info.get('visitor_id'):
                status = 'known' if track_info.get('status') == 'known' else 'new'
            elif track_info['confirmed_count'] >= self.false_positive_filter['required_confirmations']:
                status = 'tracking'
            else:
                status = 'detected'

            color = self.COLORS[status]

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ bounding box
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), color, 2)

            # –¢–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            label = f"ID:{track_id} {status}"
            if track_info.get('visitor_id'):
                label += f" V:{track_info['visitor_id']}"

            cv2.putText(processed_frame, label, (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

            detected_count += 1

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤)
            if (track_info['confirmed_count'] >= self.false_positive_filter['required_confirmations'] and
                    current_time - track_info.get('last_processed', 0) > self.processing_interval):

                try:
                    face_roi = frame[y:y + h, x:x + w]
                    embedding = self.get_fast_embedding(face_roi)

                    if embedding is not None:
                        visitor_id, status = self.update_visitor_database(embedding, face_roi, track_id)
                        if visitor_id:
                            track_info['visitor_id'] = visitor_id
                            track_info['status'] = status
                            processed_count += 1

                    track_info['last_processed'] = current_time

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Ü–∞: {e}")

        with self.stats_lock:
            self.recognition_stats['total_detections'] += len(faces)
            self.recognition_stats['valid_detections'] += detected_count
            self.recognition_stats['frames_processed'] += 1

        return processed_frame, detected_count, processed_count

    def resize_frame_for_display(self, frame, target_width=1280):
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            h, w = frame.shape[:2]
            if w <= target_width:
                return frame

            scale_factor = target_width / w
            new_width = target_width
            new_height = int(h * scale_factor)

            return cv2.resize(frame, (new_width, new_height))
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞: {e}")
            return frame

    def create_gallery_display(self, main_frame):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –≥–∞–ª–µ—Ä–µ–µ–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            main_height, main_width = main_frame.shape[:2]

            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–Ω–µ–ª–∏ –¥–ª—è –≥–∞–ª–µ—Ä–µ–∏
            gallery_height = 180
            combined_width = main_width

            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            combined_frame = np.zeros((main_height + gallery_height, combined_width, 3), dtype=np.uint8)
            combined_frame[0:main_height, 0:main_width] = main_frame

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥–∞–ª–µ—Ä–µ–∏
            cv2.putText(combined_frame, "Current Visitors Gallery", (10, main_height + 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –≥–∞–ª–µ—Ä–µ–∏
            current_time = time.time()
            if current_time - self.last_gallery_cleanup > self.gallery_cleanup_interval:
                with self.gallery_lock:
                    self.current_visitors_gallery = {
                        k: v for k, v in self.current_visitors_gallery.items()
                        if current_time - v['last_seen'] < 300  # 5 –º–∏–Ω—É—Ç
                    }
                self.last_gallery_cleanup = current_time

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –≥–∞–ª–µ—Ä–µ–∏
            gallery_x = 10
            for track_id, visitor_info in list(self.current_visitors_gallery.items())[:8]:
                if 'photo' in visitor_info:
                    photo = visitor_info['photo']
                    photo_resized = cv2.resize(photo, (120, 120))

                    # –†–∞–∑–º–µ—â–µ–Ω–∏–µ —Ñ–æ—Ç–æ –≤ –≥–∞–ª–µ—Ä–µ–µ
                    y_start = main_height + 40
                    y_end = y_start + 120
                    x_end = gallery_x + 120

                    if x_end < combined_width:
                        combined_frame[y_start:y_end, gallery_x:gallery_x + 120] = photo_resized

                        # –ü–æ–¥–ø–∏—Å—å
                        label = f"ID:{visitor_info.get('visitor_id', track_id)}"
                        cv2.putText(combined_frame, label, (gallery_x, main_height + 165),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                        gallery_x += 130

            return combined_frame

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")
            return main_frame

    def processing_worker(self):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤"""
        logger.info("üîÑ –ó–∞–ø—É—â–µ–Ω –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        while not self.stop_processing:
            try:
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞–¥—Ä–∞ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                frame_data = self.frame_queue.get(timeout=1.0)
                if frame_data is None:
                    break

                frame, frame_time = frame_data

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
                processed_frame, detected, processed = self.process_frame_realtime(frame)

                # –ü–æ–º–µ—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –æ—á–µ—Ä–µ–¥—å
                if not self.results_queue.full():
                    self.results_queue.put((processed_frame, detected, processed))

                self.frame_queue.task_done()

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                time.sleep(0.1)

        logger.info("üõë –ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    def start_processing_thread(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.stop_processing = False
        self.processing_thread = threading.Thread(target=self.processing_worker)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        logger.info("‚úÖ –ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—É—â–µ–Ω")

    def start_analysis(self, rtsp_url):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≤–µ—Ä—Å–∏–∏ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –ª—é–±–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è...")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        self.start_processing_thread()
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω - —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ª–∏—Ü–∞ –ª—é–±–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞!")
        logger.info("üí° –°–∏—Å—Ç–µ–º–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ª–∏—Ü –æ—Ç 20x20 –¥–æ 300x300 –ø–∏–∫—Å–µ–ª–µ–π")

        window_name = 'Trassir Analytics - ANY DISTANCE'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 900)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("üì° –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–º–µ—Ä–æ–π...")
                    time.sleep(2)
                    continue

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
                processed_frame, detected, processed = self.process_frame_realtime(frame)
                display_frame = self.resize_frame_for_display(processed_frame, target_width=1280)
                display_with_gallery = self.create_gallery_display(display_frame)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                stats_text = [
                    f"ANY DISTANCE - REALISTIC FILTERS",
                    f"Valid detections: {detected}",
                    f"Visitors processed: {processed}",
                    f"Active tracks: {len(self.face_tracks)}",
                    f"In gallery: {len(self.current_visitors_gallery)}",
                    f"Rejected: {self.recognition_stats['rejected_detections']}",
                    f"FPS: {self.current_fps:.1f}",
                    f"Press 'q' to quit"
                ]

                overlay = display_with_gallery.copy()
                cv2.rectangle(overlay, (0, 0), (550, 220), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.7, display_with_gallery, 0.3, 0, display_with_gallery)

                for i, text in enumerate(stats_text):
                    cv2.putText(display_with_gallery, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                cv2.imshow(window_name, display_with_gallery)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C...")
        finally:
            self.stop_processing = True
            if self.processing_thread:
                self.processing_thread.join(timeout=2.0)
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   –í—Å–µ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")
            logger.info(f"   –ù–æ–≤—ã—Ö —Å–æ–∑–¥–∞–Ω–æ: {self.recognition_stats['new_visitors']}")
            logger.info(f"   –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.recognition_stats['known_visitors']}")
            logger.info(f"   –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {self.recognition_stats['rejected_detections']}")
            if self.recognition_stats['quality_rejections']:
                logger.info(f"   –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π: {dict(self.recognition_stats['quality_rejections'])}")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = RealisticTrassirCounter(
        processing_interval=1.0,
        similarity_threshold=0.65,
        tracking_threshold=0.50
    )

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()