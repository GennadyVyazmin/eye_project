# video_analytics_trassir_realistic.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
from deepface import DeepFace
import logging
import threading
from queue import Queue
from collections import deque, defaultdict
import os
import shutil

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RealisticTrassirCounter:
    def __init__(self, processing_interval=1.0, similarity_threshold=0.65, tracking_threshold=0.50):
        """
        –í–µ—Ä—Å–∏—è —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç –∫–∞–º–µ—Ä—ã
        """
        self.conn = sqlite3.connect('visitors_trassir_realistic.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.similarity_threshold = similarity_threshold
        self.tracking_threshold = tracking_threshold

        # –¶–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        self.COLORS = {
            'detected': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –ª–∏—Ü–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
            'tracking': (255, 255, 0),  # –ñ–µ–ª—Ç—ã–π - —Å–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫
            'known': (0, 255, 255),  # –ì–æ–ª—É–±–æ–π - –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            'new': (0, 0, 255),  # –ö—Ä–∞—Å–Ω—ã–π - –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ë–î
            'analyzing': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –∞–Ω–∞–ª–∏–∑ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
            'rejected': (128, 128, 128)  # –°–µ—Ä—ã–π - –æ—Ç—Å–µ—è–Ω –ª–æ–∂–Ω—ã–π –æ–±—ä–µ–∫—Ç
        }

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
        self.photos_dir = "visitor_photos_realistic"
        self.current_session_dir = "current_session"
        self._create_directories()

        # –¢—Ä–µ–∫–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.last_processing_time = 0
        self.known_visitors_cache = {}
        self.frame_count = 0

        # –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü
        self.face_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 8.0

        # –ì–∞–ª–µ—Ä–µ—è —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π —Å –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–æ–π
        self.current_visitors_gallery = {}
        self.gallery_max_size = 8
        self.gallery_cleanup_interval = 60.0
        self.last_gallery_cleanup = time.time()
        self.photo_size = (120, 160)

        # –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ï —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        self.false_positive_filter = {
            'min_face_ratio': 0.008,  # –û–ß–ï–ù–¨ –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞ (1-2% –∫–∞–¥—Ä–∞)
            'max_face_ratio': 0.30,  # –î–æ 30% –∫–∞–¥—Ä–∞ (–∫—Ä—É–ø–Ω—ã–π –ø–ª–∞–Ω)
            'min_aspect_ratio': 0.5,  # –®–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            'max_aspect_ratio': 2.0,
            'min_brightness': 15,  # –û—á–µ–Ω—å —Ç–µ–º–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            'max_brightness': 245,  # –û—á–µ–Ω—å —è—Ä–∫–∏–µ —É—Å–ª–æ–≤–∏—è
            'edge_threshold': 10,  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —á–µ—Ç–∫–æ—Å—Ç—å
            'required_confirmations': 2,
            'min_face_width': 40,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
            'min_face_height': 40  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recognition_stats = {
            'total_detections': 0,
            'valid_detections': 0,
            'rejected_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'frames_processed': 0,
            'quality_rejections': defaultdict(int)
        }
        self.last_log_time = time.time()

        # –û—á–µ—Ä–µ–¥—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.frame_queue = Queue(maxsize=1)
        self.results_queue = Queue()

        # –î–µ—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ü —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –¥–∞–ª—å–Ω–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        self.alt_face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml'
        )

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self._load_known_visitors()

        # –ü–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processing_thread = None
        self.stop_processing = False

        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        logger.info("üéØ –°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω—ã –ø–∞–ø–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ: {self.photos_dir}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_embedding BLOB,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                confirmed_count INTEGER DEFAULT 1,
                photo_path TEXT,
                quality_score REAL DEFAULT 1.0
            )
        ''')
        self.conn.commit()

    def _load_known_visitors(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT id, face_embedding, photo_path FROM visitors")
        visitors = cursor.fetchall()

        self.known_visitors_cache.clear()
        for visitor_id, embedding_blob, photo_path in visitors:
            if embedding_blob:
                try:
                    embedding = np.frombuffer(embedding_blob, dtype=np.float32)
                    self.known_visitors_cache[visitor_id] = embedding
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}: {e}")

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")

    def setup_rtsp_camera(self, rtsp_url):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ RTSP –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        logger.info(f"üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)

        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 15)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))

        for _ in range(10):
            cap.read()

        if cap.isOpened():
            ret, test_frame = cap.read()
            if ret:
                logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {test_frame.shape[1]}x{test_frame.shape[0]}")
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                h, w = test_frame.shape[:2]
                logger.info(f"üìê –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –ª–∏—Ü –Ω–∞ —ç—Ç–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏:")
                logger.info(f"   - –ú–∞–ª–µ–Ω—å–∫–æ–µ –ª–∏—Ü–æ (–¥–∞–ª–µ–∫–æ): {int(w * 0.02)}x{int(h * 0.02)} –ø–∏–∫—Å–µ–ª–µ–π")
                logger.info(f"   - –°—Ä–µ–¥–Ω–µ–µ –ª–∏—Ü–æ: {int(w * 0.08)}x{int(h * 0.08)} –ø–∏–∫—Å–µ–ª–µ–π")
                logger.info(f"   - –ö—Ä—É–ø–Ω–æ–µ –ª–∏—Ü–æ (–±–ª–∏–∑–∫–æ): {int(w * 0.15)}x{int(h * 0.15)} –ø–∏–∫—Å–µ–ª–µ–π")
            else:
                logger.error("‚ùå –ö–∞–º–µ—Ä–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")

        return cap

    def analyze_face_quality(self, face_image, bbox, frame_size):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏"""
        try:
            x, y, w, h = bbox
            frame_height, frame_width = frame_size

            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ê–ë–°–û–õ–Æ–¢–ù–û–ì–û —Ä–∞–∑–º–µ—Ä–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö (–≤–∞–∂–Ω–µ–µ —á–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ)
            logger.debug(f"üìè –ê–±—Å–æ–ª—é—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {w}x{h} –ø–∏–∫—Å–µ–ª–µ–π")

            if w < self.false_positive_filter['min_face_width']:
                self.recognition_stats['quality_rejections']['small_width'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è —à–∏—Ä–∏–Ω–∞ ({w} < {self.false_positive_filter['min_face_width']})"
            if h < self.false_positive_filter['min_face_height']:
                self.recognition_stats['quality_rejections']['small_height'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –≤—ã—Å–æ—Ç–∞ ({h} < {self.false_positive_filter['min_face_height']})"

            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û–ì–û —Ä–∞–∑–º–µ—Ä–∞ (–≤—Ç–æ—Ä–∏—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π)
            face_area = w * h
            frame_area = frame_width * frame_height
            face_ratio = face_area / frame_area

            logger.debug(f"üìê –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {face_ratio:.4f} ({w}x{h} –ø–∏–∫—Å)")

            if face_ratio < self.false_positive_filter['min_face_ratio']:
                self.recognition_stats['quality_rejections']['small_ratio'] += 1
                # –ù–ï –æ—Ç–∫–ª–æ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∏–∑-–∑–∞ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è, –µ—Å–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π
                if w < 60 or h < 60:  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                    return False, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ ({face_ratio:.4f})"
                else:
                    logger.debug(f"‚ö†Ô∏è  –ú–∞–ª–µ–Ω—å–∫–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ, –Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä - –ø—Ä–∏–Ω–∏–º–∞–µ–º")

            if face_ratio > self.false_positive_filter['max_face_ratio']:
                self.recognition_stats['quality_rejections']['large_ratio'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ ({face_ratio:.4f})"

            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
            aspect_ratio = w / h
            logger.debug(f"‚öñÔ∏è –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω: {aspect_ratio:.2f}")

            if aspect_ratio < self.false_positive_filter['min_aspect_ratio']:
                self.recognition_stats['quality_rejections']['narrow'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º —É–∑–∫–æ–µ ({aspect_ratio:.2f})"
            if aspect_ratio > self.false_positive_filter['max_aspect_ratio']:
                self.recognition_stats['quality_rejections']['wide'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º —à–∏—Ä–æ–∫–æ–µ ({aspect_ratio:.2f})"

            # 4. –£–°–ò–õ–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏—Ü–æ (–∞ –Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π –æ–±—ä–µ–∫—Ç)
            gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —è—Ä–∫–æ—Å—Ç–∏
            brightness = np.mean(gray_face)
            logger.debug(f"üí° –Ø—Ä–∫–æ—Å—Ç—å: {brightness:.1f}")

            if brightness < self.false_positive_filter['min_brightness']:
                self.recognition_stats['quality_rejections']['dark'] += 1
                # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü –¥–æ–ø—É—Å–∫–∞–µ–º –º–µ–Ω—å—à—É—é —è—Ä–∫–æ—Å—Ç—å
                if w > 80:  # –¢–æ–ª—å–∫–æ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –ª–∏—Ü —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —è—Ä–∫–æ—Å—Ç–∏
                    return False, f"–°–ª–∏—à–∫–æ–º —Ç–µ–º–Ω–æ–µ ({brightness:.1f})"
                else:
                    logger.debug(f"‚ö†Ô∏è  –¢–µ–º–Ω–æ–µ, –Ω–æ –º–∞–ª–µ–Ω—å–∫–æ–µ –ª–∏—Ü–æ - –ø—Ä–∏–Ω–∏–º–∞–µ–º")

            if brightness > self.false_positive_filter['max_brightness']:
                self.recognition_stats['quality_rejections']['bright'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º —Å–≤–µ—Ç–ª–æ–µ ({brightness:.1f})"

            # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ç–∫–æ—Å—Ç–∏ (–¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∞—è)
            laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
            logger.debug(f"üîç –ß–µ—Ç–∫–æ—Å—Ç—å (–ª–∞–ø–ª–∞—Å–∏–∞–Ω): {laplacian_var:.1f}")

            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ —á–µ—Ç–∫–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–∏—Ü–∞
            dynamic_edge_threshold = max(self.false_positive_filter['edge_threshold'],
                                         min(30, 50 - w / 5))  # –ß–µ–º –º–µ–Ω—å—à–µ –ª–∏—Ü–æ, —Ç–µ–º –Ω–∏–∂–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

            if laplacian_var < dynamic_edge_threshold:
                self.recognition_stats['quality_rejections']['blurry'] += 1
                logger.debug(f"‚ö†Ô∏è  –ù–∏–∑–∫–∞—è —á–µ—Ç–∫–æ—Å—Ç—å ({laplacian_var:.1f} < {dynamic_edge_threshold:.1f}), –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
                # –ù–ï –æ—Ç–∫–ª–æ–Ω—è–µ–º –∏–∑-–∑–∞ —á–µ—Ç–∫–æ—Å—Ç–∏ –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü

            # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            contrast = np.std(gray_face)
            logger.debug(f"üé® –ö–æ–Ω—Ç—Ä–∞—Å—Ç: {contrast:.1f}")

            if contrast < 3:  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                self.recognition_stats['quality_rejections']['uniform'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–∞—è –æ–±–ª–∞—Å—Ç—å ({contrast:.1f})"

            # 7. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞: –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –æ—Ç—Å–µ–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            hist = cv2.calcHist([gray_face], [0], None, [8], [0, 256])
            hist_std = np.std(hist)
            if hist_std < 100 and w > 100:  # –î–ª—è –∫—Ä—É–ø–Ω—ã—Ö –ª–∏—Ü –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—ã
                self.recognition_stats['quality_rejections']['simple_texture'] += 1
                return False, f"–°–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–∞—è —Ç–µ–∫—Å—Ç—É—Ä–∞ ({hist_std:.1f})"

            return True, f"‚úÖ –õ–∏—Ü–æ {w}x{h} –ø–∏–∫—Å (—è—Ä–∫–æ—Å—Ç—å: {brightness:.1f}, —á–µ—Ç–∫–æ—Å—Ç—å: {laplacian_var:.1f})"

        except Exception as e:
            self.recognition_stats['quality_rejections']['error'] += 1
            return False, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {e}"

    def detect_faces_robust(self, frame):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –†–ê–ó–ù–´–• —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        frame_size = gray.shape

        all_faces = []

        # –ú–ù–û–ì–û–£–†–û–í–ù–ï–í–ê–Ø –¥–µ—Ç–µ–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –ª–∏—Ü
        detection_params = [
            # –£—Ä–æ–≤–µ–Ω—å 1: –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞ (–¥–∞–ª–µ–∫–∏–µ –ª—é–¥–∏)
            {
                'scaleFactor': 1.05,
                'minNeighbors': 3,
                'minSize': (20, 20),  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞
                'maxSize': (80, 80),
                'name': 'tiny_faces'
            },
            # –£—Ä–æ–≤–µ–Ω—å 2: –°—Ä–µ–¥–Ω–∏–µ –ª–∏—Ü–∞ (–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ)
            {
                'scaleFactor': 1.1,
                'minNeighbors': 4,
                'minSize': (40, 40),
                'maxSize': (150, 150),
                'name': 'medium_faces'
            },
            # –£—Ä–æ–≤–µ–Ω—å 3: –ö—Ä—É–ø–Ω—ã–µ –ª–∏—Ü–∞ (–±–ª–∏–∑–∫–æ –∫ –∫–∞–º–µ—Ä–µ)
            {
                'scaleFactor': 1.1,
                'minNeighbors': 5,
                'minSize': (80, 80),
                'maxSize': (300, 300),
                'name': 'large_faces'
            }
        ]

        total_raw_detections = 0
        valid_count = 0
        rejected_count = 0

        for params in detection_params:
            # –î–µ—Ç–µ–∫—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã–º –∫–∞—Å–∫–∞–¥–æ–º
            faces1 = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=params['scaleFactor'],
                minNeighbors=params['minNeighbors'],
                minSize=params['minSize'],
                maxSize=params['maxSize'],
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            # –î–µ—Ç–µ–∫—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º –∫–∞—Å–∫–∞–¥–æ–º
            faces2 = self.alt_face_cascade.detectMultiScale(
                gray,
                scaleFactor=params['scaleFactor'],
                minNeighbors=params['minNeighbors'] - 1,  # –ë–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π
                minSize=params['minSize'],
                maxSize=params['maxSize'],
                flags=cv2.CASCADE_SCALE_IMAGE
            )

            total_raw_detections += len(faces1) + len(faces2)
            logger.debug(f"üîç {params['name']}: –æ—Å–Ω–æ–≤–Ω–æ–π {len(faces1)}, –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π {len(faces2)}")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            face_set = set()

            for faces in [faces1, faces2]:
                for (x, y, w, h) in faces:
                    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –±–ª–∏–∑–∫–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
                    face_key = (x // 15, y // 15, w // 15, h // 15)
                    if face_key in face_set:
                        continue

                    face_set.add(face_key)

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ª–∏—Ü–∞
                    face_roi = frame[y:y + h, x:x + w]
                    is_valid, quality_msg = self.analyze_face_quality(face_roi, (x, y, w, h), frame_size)

                    if is_valid:
                        all_faces.append((x, y, w, h))
                        valid_count += 1
                        logger.info(f"‚úÖ –ü—Ä–∏–Ω—è—Ç–æ {params['name']} {w}x{h}: {quality_msg}")
                    else:
                        rejected_count += 1
                        if w >= 40:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
                            logger.info(f"‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–æ {params['name']} {w}x{h}: {quality_msg}")

        logger.info(
            f"üìä –ú–ù–û–ì–û–£–†–û–í–ù–ï–í–ê–Ø –¥–µ—Ç–µ–∫—Ü–∏—è: —Å—ã—Ä—ã—Ö {total_raw_detections}, –ø—Ä–∏–Ω—è—Ç–æ {valid_count}, –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ {rejected_count}")
        self.recognition_stats['rejected_detections'] += rejected_count

        return all_faces

    def get_fast_embedding(self, face_image):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ø–æ–¥ –º–∞–ª–µ–Ω—å–∫–∏–µ –ª–∏—Ü–∞"""
        try:
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–µ—Å–∞–π–∑ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ª–∏—Ü–∞
            h, w = face_image.shape[:2]

            if w < 60 or h < 60:
                # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –ª–∏—Ü –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π
                target_size = max(80, min(w, h))
                face_resized = cv2.resize(face_image, (target_size, target_size))
                logger.debug(f"üîç –ú–∞–ª–µ–Ω—å–∫–æ–µ –ª–∏—Ü–æ {w}x{h}, —Ä–µ—Å–∞–π–∑ –¥–æ {target_size}x{target_size}")
            else:
                # –î–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –ª–∏—Ü —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                face_resized = cv2.resize(face_image, (160, 160))

            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)

            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            result = DeepFace.represent(
                face_rgb,
                model_name='Facenet',
                enforce_detection=False,
                detector_backend='opencv',
                align=False
            )

            embedding = np.array(result[0]['embedding'], dtype=np.float32)

            # –ú—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            if np.all(embedding == 0):
                logger.warning("‚ùå –ù—É–ª–µ–≤–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥")
                return None

            norm = np.linalg.norm(embedding)
            if norm < 0.005:  # –û—á–µ–Ω—å –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
                logger.warning(f"‚ùå –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –Ω–æ—Ä–º–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {norm}")
                return None

            logger.debug(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω, –Ω–æ—Ä–º–∞: {norm:.4f}")
            return embedding

        except Exception as e:
            logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None

    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏
    # (calculate_similarity, find_best_match, update_face_tracking –∏ —Ç.–¥.)

    def start_analysis(self, rtsp_url):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≤–µ—Ä—Å–∏–∏ —Å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ú–ò —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –ª—é–±–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è...")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        self.start_processing_thread()
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω - —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ª–∏—Ü–∞ –ª—é–±–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞!")
        logger.info("üí° –°–∏—Å—Ç–µ–º–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ª–∏—Ü –æ—Ç 20x20 –¥–æ 300x300 –ø–∏–∫—Å–µ–ª–µ–π")

        window_name = 'Trassir Analytics - ANY DISTANCE'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 900)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("üì° –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–º–µ—Ä–æ–π...")
                    time.sleep(2)
                    continue

                processed_frame, detected, processed = self.process_frame_realtime(frame)
                display_frame = self.resize_frame_for_display(processed_frame, target_width=1280)
                display_with_gallery = self.create_gallery_display(display_frame)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                stats_text = [
                    f"ANY DISTANCE - REALISTIC FILTERS",
                    f"Valid detections: {detected}",
                    f"Visitors processed: {processed}",
                    f"Active tracks: {len(self.face_tracks)}",
                    f"In gallery: {len(self.current_visitors_gallery)}",
                    f"Rejected: {self.recognition_stats['rejected_detections']}",
                    f"FPS: {self.current_fps:.1f}",
                    f"Press 'q' to quit"
                ]

                overlay = display_with_gallery.copy()
                cv2.rectangle(overlay, (0, 0), (550, 220), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.7, display_with_gallery, 0.3, 0, display_with_gallery)

                for i, text in enumerate(stats_text):
                    cv2.putText(display_with_gallery, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                cv2.imshow(window_name, display_with_gallery)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C...")
        finally:
            self.stop_processing = True
            if self.processing_thread:
                self.processing_thread.join(timeout=2.0)
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   –í—Å–µ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors_cache)}")
            logger.info(f"   –ù–æ–≤—ã—Ö —Å–æ–∑–¥–∞–Ω–æ: {self.recognition_stats['new_visitors']}")
            logger.info(f"   –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.recognition_stats['known_visitors']}")
            logger.info(f"   –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {self.recognition_stats['rejected_detections']}")
            if self.recognition_stats['quality_rejections']:
                logger.info(f"   –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π: {dict(self.recognition_stats['quality_rejections'])}")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = RealisticTrassirCounter(
        processing_interval=1.0,
        similarity_threshold=0.65,
        tracking_threshold=0.50
    )

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()