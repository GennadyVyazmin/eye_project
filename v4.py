# video_analytics_trassir_standalone.py
import cv2
import numpy as np
import sqlite3
import datetime
import time
import logging
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('face_detection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class StandaloneTrassirCounter:
    def __init__(self, processing_interval=1.0, tracking_threshold=0.7):
        """
        –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–∫—Ä–æ–º–µ OpenCV)
        """
        self.conn = sqlite3.connect('visitors_trassir_standalone.db', check_same_thread=False)
        self._init_database()

        self.processing_interval = processing_interval
        self.tracking_threshold = tracking_threshold

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self.min_face_size = 80
        self.max_face_size = 400
        self.min_confidence = 0.6

        # –¶–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
        self.COLORS = {
            'detected': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –ª–∏—Ü–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
            'tracking': (255, 255, 0),  # –ñ–µ–ª—Ç—ã–π - —Å–æ–∑–¥–∞–Ω —Ç—Ä–µ–∫
            'known': (0, 255, 255),  # –ì–æ–ª—É–±–æ–π - –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
            'new': (0, 0, 255),  # –ö—Ä–∞—Å–Ω—ã–π - –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –ë–î
            'analyzing': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –∞–Ω–∞–ª–∏–∑ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
            'filtered': (128, 128, 128)  # –°–µ—Ä—ã–π - –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ
        }

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
        self.photos_dir = "visitor_photos_standalone"
        self.current_session_dir = "current_session"
        self._create_directories()

        # –¢—Ä–µ–∫–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.last_processing_time = 0
        self.known_visitors = {}
        self.next_visitor_id = 1

        # –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü
        self.face_tracks = {}
        self.next_track_id = 1
        self.track_max_age = 5.0

        # –ì–∞–ª–µ—Ä–µ—è —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self.current_visitors_gallery = {}
        self.gallery_max_size = 8
        self.photo_size = (120, 160)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recognition_stats = {
            'total_detections': 0,
            'new_visitors': 0,
            'known_visitors': 0,
            'frames_processed': 0,
            'filtered_detections': 0
        }
        self.last_log_time = time.time()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ OpenCV
        self.setup_opencv_detectors()

        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ FPS
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0

        logger.info("üéØ –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (—Ç–æ–ª—å–∫–æ OpenCV)")

    def setup_opencv_detectors(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ OpenCV"""
        try:
            # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Å–∫–∞–¥—ã –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü
            self.face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            )
            self.face_cascade_alt = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml'
            )
            self.profile_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_profileface.xml'
            )

            logger.info("‚úÖ –î–µ—Ç–µ–∫—Ç–æ—Ä—ã OpenCV –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤: {e}")
            raise

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ"""
        os.makedirs(self.photos_dir, exist_ok=True)
        os.makedirs(os.path.join(self.photos_dir, self.current_session_dir), exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω—ã –ø–∞–ø–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ: {self.photos_dir}")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS visitors (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                last_updated TIMESTAMP,
                photo_path TEXT,
                facial_features BLOB
            )
        ''')
        self.conn.commit()

    def detect_faces_robust(self, frame):
        """–ù–∞–¥–µ–∂–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞—Å–∫–∞–¥–æ–≤"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # –î–µ—Ç–µ–∫—Ü–∏—è —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏—Ü
        faces1 = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=6,
            minSize=(self.min_face_size, self.min_face_size),
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        faces2 = self.face_cascade_alt.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(self.min_face_size, self.min_face_size),
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        # –î–µ—Ç–µ–∫—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã—Ö –ª–∏—Ü
        faces3 = self.profile_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(self.min_face_size, self.min_face_size),
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        all_faces = []
        seen_positions = set()

        for faces in [faces1, faces2, faces3]:
            for (x, y, w, h) in faces:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
                if w > self.max_face_size or h > self.max_face_size:
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã (–≥—Ä—É–±–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞)
                pos_key = (x // 20, y // 20, w // 20, h // 20)
                if pos_key in seen_positions:
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ä–µ–≥–∏–æ–Ω–∞
                if not self.is_valid_face_region(frame, x, y, w, h):
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –ª–∏—Ü–æ
                face_roi = gray[y:y + h, x:x + w]
                if self.is_likely_face(face_roi):
                    all_faces.append((x, y, w, h))
                    seen_positions.add(pos_key)

        logger.info(f"üîç –î–µ—Ç–µ–∫—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(all_faces)} –ª–∏—Ü")
        return all_faces

    def is_valid_face_region(self, frame, x, y, w, h):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ä–µ–≥–∏–æ–Ω–∞ –ª–∏—Ü–∞"""
        h_total, w_total = frame.shape[:2]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã—Ö–æ–¥–∞ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
        if x < 0 or y < 0 or x + w > w_total or y + h > h_total:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        if w < self.min_face_size or h < self.min_face_size:
            return False
        if w > self.max_face_size or h > self.max_face_size:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
        aspect_ratio = w / h
        if aspect_ratio < 0.6 or aspect_ratio > 1.8:
            return False

        return True

    def is_likely_face(self, face_roi):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ä–µ–≥–∏–æ–Ω –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –≤—Å–µ–≥–æ —è–≤–ª—è–µ—Ç—Å—è –ª–∏—Ü–æ–º"""
        if face_roi.size == 0:
            return False

        h, w = face_roi.shape

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (–ª–∏—Ü–∞ –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç —Ö–æ—Ä–æ—à–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç)
        std_dev = np.std(face_roi)
        if std_dev < 15:  # –°–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–∞—è —Ç–µ–∫—Å—Ç—É—Ä–∞
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–º–º–µ—Ç—Ä–∏–∏ (–ª–∏—Ü–∞ –æ–±—ã—á–Ω–æ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã)
        left_half = face_roi[:, :w // 2]
        right_half = face_roi[:, w // 2:]

        # –ó–µ—Ä–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∞–≤–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        right_flipped = cv2.flip(right_half, 1)

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º
        hist_left = cv2.calcHist([left_half], [0], None, [8], [0, 256])
        hist_right = cv2.calcHist([right_flipped], [0], None, [8], [0, 256])

        correlation = cv2.compareHist(hist_left, hist_right, cv2.HISTCMP_CORREL)

        return correlation > 0.3  # –£–º–µ—Ä–µ–Ω–Ω–∞—è —Å–∏–º–º–µ—Ç—Ä–∏—è

    def validate_human_features(self, face_image):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —á–µ–ª–æ–≤–µ–∫–∞"""
        if face_image.size == 0:
            return False

        h, w = face_image.shape[:2]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        if w < 50 or h < 50 or w > 400 or h > 400:
            return False

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–≤–µ—Ç–æ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–∫–æ–∂–∞ —á–µ–ª–æ–≤–µ–∫–∞)
            hsv = cv2.cvtColor(face_image, cv2.COLOR_BGR2HSV)

            # –ú–∞—Å–∫–∞ –¥–ª—è —Ü–≤–µ—Ç–æ–≤ –∫–æ–∂–∏
            skin_lower = np.array([0, 20, 70], dtype=np.uint8)
            skin_upper = np.array([20, 255, 255], dtype=np.uint8)
            skin_mask = cv2.inRange(hsv, skin_lower, skin_upper)

            # –ü—Ä–æ—Ü–µ–Ω—Ç –ø–∏–∫—Å–µ–ª–µ–π –∫–æ–∂–∏
            skin_ratio = np.sum(skin_mask > 0) / (w * h)

            # –î–ª—è –ª–∏—Ü –æ–±—ã—á–Ω–æ 15-50% –ø–∏–∫—Å–µ–ª–µ–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ü–≤–µ—Ç—É –∫–æ–∂–∏
            return 0.1 < skin_ratio < 0.7
        except:
            return True  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –¥–∞–µ–º —à–∞–Ω—Å

    def extract_robust_features(self, face_image):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–¥–µ–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞"""
        try:
            # –†–µ—Å–∞–π–∑ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
            resized = cv2.resize(face_image, (100, 100))

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ä–∞–∑–Ω—ã–µ —Ü–≤–µ—Ç–æ–≤—ã–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
            gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
            hsv = cv2.cvtColor(resized, cv2.COLOR_BGR2HSV)
            lab = cv2.cvtColor(resized, cv2.COLOR_BGR2LAB)

            features = []

            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –ø–æ –∫–∞–Ω–∞–ª–∞–º
            for i, channel in enumerate([gray, hsv[:, :, 0], hsv[:, :, 1], lab[:, :, 0]]):
                hist = cv2.calcHist([channel], [0], None, [16], [0, 256])
                hist = cv2.normalize(hist, hist).flatten()
                features.extend(hist)

            # –¢–µ–∫—Å—Ç—É—Ä–∞ - –ª–æ–∫–∞–ª—å–Ω—ã–π –±–∏–Ω–∞—Ä–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            texture_features = self.extract_texture_features(gray)
            features.extend(texture_features)

            # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
            geometric_features = self.extract_geometric_features(gray)
            features.extend(geometric_features)

            features = np.array(features, dtype=np.float32)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if np.linalg.norm(features) > 0:
                features = features / np.linalg.norm(features)

            return features
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None

    def extract_texture_features(self, gray_image):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π LBP (Local Binary Pattern)
        h, w = gray_image.shape
        texture_features = []

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ä–µ–≥–∏–æ–Ω—ã –∏ –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for i in range(0, h, 25):
            for j in range(0, w, 25):
                region = gray_image[i:min(i + 25, h), j:min(j + 25, w)]
                if region.size > 0:
                    texture_features.append(np.mean(region))
                    texture_features.append(np.std(region))

        return texture_features[:8]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

    def extract_geometric_features(self, gray_image):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        features = []

        # –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã
        grad_x = cv2.Sobel(gray_image, cv2.CV_32F, 1, 0)
        grad_y = cv2.Sobel(gray_image, cv2.CV_32F, 0, 1)

        magnitude, angle = cv2.cartToPolar(grad_x, grad_y)

        features.append(np.mean(magnitude))
        features.append(np.std(magnitude))
        features.append(np.mean(angle))
        features.append(np.std(angle))

        return features

    def calculate_feature_similarity(self, features1, features2):
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if features1 is None or features2 is None:
            return 0.0

        try:
            # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
            similarity = np.dot(features1, features2)
            return max(0.0, min(1.0, similarity))
        except:
            return 0.0

    def update_face_tracking(self, current_faces, timestamp):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –ª–∏—Ü –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏"""
        updated_faces = []

        for face_data in current_faces:
            features = face_data['features']
            coords = face_data['coords']
            face_image = face_data['face_image']

            best_track_id = None
            best_similarity = 0.0

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ç—Ä–µ–∫–∏
            current_tracks = list(self.face_tracks.keys())
            for track_id in current_tracks:
                if timestamp - self.face_tracks[track_id]['last_seen'] > self.track_max_age:
                    logger.debug(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ç—Ä–µ–∫ {track_id}")
                    del self.face_tracks[track_id]

            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ç—Ä–µ–∫–∞–º–∏
            for track_id, track_data in self.face_tracks.items():
                similarity = self.calculate_feature_similarity(features, track_data['features'])
                if similarity > best_similarity and similarity > self.tracking_threshold:
                    best_similarity = similarity
                    best_track_id = track_id

            if best_track_id is not None:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–∫
                self.face_tracks[best_track_id].update({
                    'features': features,
                    'last_seen': timestamp,
                    'coords': coords,
                    'face_image': face_image
                })
                face_data['track_id'] = best_track_id
                face_data['visitor_id'] = self.face_tracks[best_track_id].get('visitor_id')
                face_data['status'] = 'tracking'
                face_data['similarity'] = best_similarity
                logger.debug(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω —Ç—Ä–µ–∫ {best_track_id}, —Å—Ö–æ–∂–µ—Å—Ç—å: {best_similarity:.3f}")
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–∫
                track_id = self.next_track_id
                self.next_track_id += 1
                self.face_tracks[track_id] = {
                    'features': features,
                    'last_seen': timestamp,
                    'coords': coords,
                    'face_image': face_image,
                    'visitor_id': None,
                    'created_at': timestamp
                }
                face_data['track_id'] = track_id
                face_data['status'] = 'tracking'
                face_data['similarity'] = 0.0
                logger.info(f"üéØ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç—Ä–µ–∫ {track_id}")

            updated_faces.append(face_data)

        return updated_faces

    def confirm_visitor_identity(self, track_id, face_data):
        """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        track_data = self.face_tracks.get(track_id)
        if not track_data:
            return None

        features = face_data['features']
        face_image = face_data['face_image']
        timestamp = time.time()

        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å visitor_id, –æ–±–Ω–æ–≤–ª—è–µ–º –µ–≥–æ
        if track_data['visitor_id']:
            visitor_id = track_data['visitor_id']
            self.recognition_stats['known_visitors'] += 1
            face_data['status'] = 'known'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
            self.update_visitor_gallery(visitor_id, face_image, 'known')

            logger.debug(f"‚ôªÔ∏è  –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id}")
            return visitor_id

        # –ò—â–µ–º –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å—Ä–µ–¥–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö
        visitor_id, similarity = self.find_best_match(features)

        if similarity > 0.75:  # –í—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è
            track_data['visitor_id'] = visitor_id
            track_data['confirmed_at'] = timestamp
            self.recognition_stats['known_visitors'] += 1
            face_data['status'] = 'known'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
            self.update_visitor_gallery(visitor_id, face_image, 'known')

            logger.info(f"üë§ –û–ü–û–ó–ù–ê–ù –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {visitor_id}, —Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f}")
            return visitor_id
        else:
            # –ñ–¥–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è
            track_duration = timestamp - track_data['created_at']
            if track_duration > 4.0:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –≤—Ä–µ–º—è –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Ç—Ä–µ–∫–∏–Ω–≥–∞
                new_visitor_id = self._create_new_visitor(features, face_image, track_id)
                if new_visitor_id:
                    self.recognition_stats['new_visitors'] += 1
                    face_data['status'] = 'new'

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≥–∞–ª–µ—Ä–µ—é
                    self.update_visitor_gallery(new_visitor_id, face_image, 'new')

                    logger.info(f"üÜï –°–û–ó–î–ê–ù –Ω–æ–≤—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å {new_visitor_id}")
                return new_visitor_id
            else:
                face_data['status'] = 'analyzing'
                logger.debug(f"‚è≥ –¢—Ä–µ–∫ {track_id} –æ–∂–∏–¥–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è ({track_duration:.1f}s)")

        return None

    def find_best_match(self, features):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å—Ä–µ–¥–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        if features is None:
            return None, 0.0

        best_match_id = None
        best_similarity = 0.0

        for visitor_id, visitor_data in self.known_visitors.items():
            similarity = self.calculate_feature_similarity(features, visitor_data['features'])
            if similarity > best_similarity:
                best_similarity = similarity
                best_match_id = visitor_id

        return best_match_id, best_similarity

    def _create_new_visitor(self, features, face_image, track_id):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        cursor = self.conn.cursor()
        now = datetime.datetime.now()

        visitor_id = None
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ
            photo_path = self.save_visitor_photo(face_image, "temp")

            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ
            features_blob = features.astype(np.float32).tobytes()
            cursor.execute(
                """INSERT INTO visitors (first_seen, last_seen, visit_count, 
                   last_updated, photo_path, facial_features) 
                   VALUES (?, ?, 1, ?, ?, ?)""",
                (now, now, now, photo_path, features_blob)
            )
            visitor_id = cursor.lastrowid

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–æ—Ç–æ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º ID
            final_photo_path = self.save_visitor_photo(face_image, visitor_id)
            cursor.execute(
                "UPDATE visitors SET photo_path = ? WHERE id = ?",
                (final_photo_path, visitor_id)
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç–∏
            self.known_visitors[visitor_id] = {
                'features': features,
                'photo_path': final_photo_path,
                'first_seen': now
            }

            self.conn.commit()

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ
            if os.path.exists(photo_path):
                os.remove(photo_path)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è: {e}")
            self.conn.rollback()
            return None

        if track_id in self.face_tracks:
            self.face_tracks[track_id]['visitor_id'] = visitor_id

        return visitor_id

    def save_visitor_photo(self, face_image, visitor_id):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è"""
        try:
            photo_clean = face_image.copy()

            height, width = photo_clean.shape[:2]
            if width < 200:
                scale = 200 / width
                new_width = 200
                new_height = int(height * scale)
                photo_clean = cv2.resize(photo_clean, (new_width, new_height))

            filename = f"visitor_{visitor_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
            filepath = os.path.join(self.photos_dir, filename)
            session_filepath = os.path.join(self.photos_dir, self.current_session_dir, filename)

            cv2.imwrite(filepath, photo_clean)
            cv2.imwrite(session_filepath, photo_clean)

            logger.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è {visitor_id}")
            return filepath

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ: {e}")
            return ""

    def update_visitor_gallery(self, visitor_id, face_image, status):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–∞–ª–µ—Ä–µ–∏ —Ç–µ–∫—É—â–∏—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            gallery_photo = face_image.copy()

            border_color = self.COLORS.get(status, (255, 255, 255))
            gallery_photo = cv2.copyMakeBorder(
                gallery_photo, 5, 25, 5, 5, cv2.BORDER_CONSTANT, value=border_color
            )

            status_text = self.get_status_text(status)
            cv2.putText(gallery_photo, f"ID: {visitor_id}", (10, gallery_photo.shape[0] - 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, border_color, 1)

            gallery_photo = cv2.resize(gallery_photo, self.photo_size)

            self.current_visitors_gallery[visitor_id] = {
                'photo': gallery_photo,
                'last_seen': time.time(),
                'status': status
            }

            if len(self.current_visitors_gallery) > self.gallery_max_size:
                oldest_visitor = min(self.current_visitors_gallery.keys(),
                                     key=lambda x: self.current_visitors_gallery[x]['last_seen'])
                del self.current_visitors_gallery[oldest_visitor]

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")

    def get_status_text(self, status):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —Å—Ç–∞—Ç—É—Å—É"""
        status_texts = {
            'detected': 'DETECTED',
            'tracking': 'TRACKING',
            'analyzing': 'ANALYZING',
            'known': 'KNOWN',
            'new': 'NEW USER',
            'filtered': 'FILTERED'
        }
        return status_texts.get(status, 'UNKNOWN')

    def get_color_by_status(self, status):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –ø–æ —Å—Ç–∞—Ç—É—Å—É"""
        return self.COLORS.get(status, (255, 255, 255))

    def create_gallery_display(self, main_frame):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–∞–ª–µ—Ä–µ–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            main_height, main_width = main_frame.shape[:2]

            gallery_width = 300
            gallery_panel = np.zeros((main_height, gallery_width, 3), dtype=np.uint8)

            cv2.putText(gallery_panel, "CURRENT VISITORS", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(gallery_panel, f"Total: {len(self.current_visitors_gallery)}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            if self.current_visitors_gallery:
                visitor_ids = sorted(self.current_visitors_gallery.keys())
                photos_per_column = 4
                photo_width, photo_height = self.photo_size
                margin = 10

                for i, visitor_id in enumerate(visitor_ids):
                    if i >= self.gallery_max_size:
                        break

                    visitor_data = self.current_visitors_gallery[visitor_id]
                    row = i % photos_per_column
                    col = i // photos_per_column

                    x = margin + col * (photo_width + margin)
                    y = 80 + row * (photo_height + margin)

                    if y + photo_height < main_height and x + photo_width < gallery_width:
                        gallery_panel[y:y + photo_height, x:x + photo_width] = visitor_data['photo']

                        status_color = self.COLORS.get(visitor_data['status'], (255, 255, 255))
                        cv2.circle(gallery_panel, (x + 10, y + 10), 5, status_color, -1)
            else:
                cv2.putText(gallery_panel, "No visitors", (50, main_height // 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 1)
                cv2.putText(gallery_panel, "in frame", (60, main_height // 2 + 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 1)

            combined_frame = np.hstack([main_frame, gallery_panel])
            return combined_frame

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥–∞–ª–µ—Ä–µ–∏: {e}")
            return main_frame

    def resize_frame_for_display(self, frame, target_width=1280):
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        height, width = frame.shape[:2]

        if width <= target_width:
            return frame

        ratio = target_width / width
        new_width = target_width
        new_height = int(height * ratio)

        return cv2.resize(frame, (new_width, new_height))

    def log_recognition_stats(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        current_time = time.time()
        if current_time - self.last_log_time >= 3.0:
            logger.info(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê: –í—Å–µ–≥–æ –≤ –±–∞–∑–µ: {len(self.known_visitors)}, "
                        f"–ê–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤: {len(self.face_tracks)}, "
                        f"–í –≥–∞–ª–µ—Ä–µ–µ: {len(self.current_visitors_gallery)}, "
                        f"–ù–æ–≤—ã—Ö –∑–∞ —Å–µ—Å—Å–∏—é: {self.recognition_stats['new_visitors']}, "
                        f"–ò–∑–≤–µ—Å—Ç–Ω—ã—Ö: {self.recognition_stats['known_visitors']}, "
                        f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {self.recognition_stats['filtered_detections']}")
            self.last_log_time = current_time

    def process_frame(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        current_time = time.time()

        # –û–±–Ω–æ–≤–ª—è–µ–º FPS
        self.fps_frame_count += 1
        if current_time - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_frame_count / (current_time - self.fps_start_time)
            self.fps_frame_count = 0
            self.fps_start_time = current_time

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        if current_time - self.last_processing_time < self.processing_interval:
            return frame, 0, 0, 0

        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
        detected_faces = self.detect_faces_robust(frame)

        processed_faces = []
        filtered_count = 0

        if detected_faces:
            self.recognition_stats['total_detections'] += len(detected_faces)
            logger.info(f"üë• –û–ë–ù–ê–†–£–ñ–ï–ù–û –û–ë–™–ï–ö–¢–û–í: {len(detected_faces)}")

            for (x, y, w, h) in detected_faces:
                face_img = frame[y:y + h, x:x + w]

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ–ª–æ–≤–µ–∫–∞
                if not self.validate_human_features(face_img):
                    filtered_count += 1
                    continue

                features = self.extract_robust_features(face_img)
                if features is not None:
                    processed_faces.append({
                        'coords': (x, y, w, h),
                        'features': features,
                        'face_image': face_img,
                        'status': 'detected'
                    })

        self.recognition_stats['filtered_detections'] += filtered_count

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫–∏–Ω–≥
        tracked_faces = self.update_face_tracking(processed_faces, current_time)

        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        processed_frame = frame.copy()
        processed_count = 0

        for face_data in tracked_faces:
            visitor_id = self.confirm_visitor_identity(face_data['track_id'], face_data)

            x, y, w, h = face_data['coords']
            status = face_data.get('status', 'detected')

            color = self.get_color_by_status(status)
            status_text = self.get_status_text(status)

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–∞–º–∫–∏
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), color, 3)
            cv2.putText(processed_frame, f'{status_text}', (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            if visitor_id:
                cv2.putText(processed_frame, f'ID: {visitor_id}', (x, y + h + 25),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                if 'similarity' in face_data:
                    cv2.putText(processed_frame, f'Sim: {face_data["similarity"]:.2f}',
                                (x, y + h + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            processed_count += 1

        self.last_processing_time = current_time
        self.log_recognition_stats()

        return processed_frame, len(detected_faces), processed_count, filtered_count

    def setup_rtsp_camera(self, rtsp_url):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ RTSP"""
        logger.info(f"üì° –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ: {rtsp_url}")
        cap = cv2.VideoCapture(rtsp_url)

        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FPS, 15)

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä—ã –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        for _ in range(10):
            cap.read()

        if cap.isOpened():
            ret, test_frame = cap.read()
            if ret:
                logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {test_frame.shape[1]}x{test_frame.shape[0]}")
            else:
                logger.error("‚ùå –ö–∞–º–µ—Ä–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")

        return cap

    def start_analysis(self, rtsp_url):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –≤–µ—Ä—Å–∏–∏ (—Ç–æ–ª—å–∫–æ OpenCV)...")

        cap = self.setup_rtsp_camera(rtsp_url)
        if not cap.isOpened():
            return

        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω")

        window_name = 'Trassir Analytics - STANDALONE (OpenCV only)'
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1600, 900)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("üì° –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–º–µ—Ä–æ–π...")
                    time.sleep(2)
                    continue

                processed_frame, detected, processed, filtered = self.process_frame(frame)
                display_frame = self.resize_frame_for_display(processed_frame, target_width=1280)
                display_with_gallery = self.create_gallery_display(display_frame)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                stats_text = [
                    f"STANDALONE ANALYTICS (OpenCV)",
                    f"Objects detected: {detected}",
                    f"Faces processed: {processed}",
                    f"Filtered: {filtered}",
                    f"Active tracks: {len(self.face_tracks)}",
                    f"In gallery: {len(self.current_visitors_gallery)}",
                    f"FPS: {self.current_fps:.1f}",
                    f"Press 'q' to quit"
                ]

                overlay = display_with_gallery.copy()
                cv2.rectangle(overlay, (0, 0), (500, 220), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.7, display_with_gallery, 0.3, 0, display_with_gallery)

                for i, text in enumerate(stats_text):
                    color = (255, 255, 255)
                    if "Filtered" in text and filtered > 0:
                        color = (0, 255, 255)
                    cv2.putText(display_with_gallery, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                cv2.imshow(window_name, display_with_gallery)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C...")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            self.conn.close()

            logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   –í—Å–µ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π: {len(self.known_visitors)}")
            logger.info(f"   –ù–æ–≤—ã—Ö —Å–æ–∑–¥–∞–Ω–æ: {self.recognition_stats['new_visitors']}")
            logger.info(f"   –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.recognition_stats['known_visitors']}")
            logger.info(f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {self.recognition_stats['filtered_detections']}")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    RTSP_URL = "rtsp://admin:admin@10.0.0.242:554/live/main"

    counter = StandaloneTrassirCounter(
        processing_interval=1.0,
        tracking_threshold=0.7
    )

    try:
        counter.start_analysis(RTSP_URL)
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()